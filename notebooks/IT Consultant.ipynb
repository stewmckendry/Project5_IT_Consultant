{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 1: Setup and Imports** <a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not already installed (uncomment below in Jupyter)\n",
    "# !pip install openai python-dotenv\n",
    "# %pip install duckduckgo-search\n",
    "\n",
    "import openai # for GPT-3\n",
    "import os # for environment variables\n",
    "from dotenv import load_dotenv # for loading environment variables\n",
    "from difflib import SequenceMatcher # for comparing strings\n",
    "import re # regular expressions\n",
    "from duckduckgo_search import DDGS # for searching DuckDuckGo (web information retrieval)\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from markdown2 import markdown # for converting markdown to HTML\n",
    "from playwright.sync_api import sync_playwright # for scraping web pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded: True\n"
     ]
    }
   ],
   "source": [
    "# Load the OpenAI API key from .env file\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check to confirm it's loaded (optional)\n",
    "print(\"✅ API key loaded:\", openai.api_key is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 2: Functions** <a id=\"2\"></a>\n",
    "## **2.1 OpenAI Functions** <a id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call OpenAI's ChatCompletion API with structured messages\n",
    "def call_openai(messages, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
    "    \"\"\"\n",
    "    Calls OpenAI's ChatCompletion API with structured messages.\n",
    "\n",
    "    Parameters:\n",
    "    messages (list): A list of message dictionaries, where each dictionary contains 'role' and 'content' keys.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "\n",
    "    Workflow:\n",
    "    1. The function takes the input parameters and calls the OpenAI ChatCompletion API.\n",
    "    2. The API returns a response containing multiple choices.\n",
    "    3. The function extracts the content of the first choice from the response.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the first choice from the API response.\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to construct system + user messages for the reasoning agent\n",
    "def build_review_prompt(report_text, history=[]):\n",
    "    \"\"\"\n",
    "    Constructs system and user messages for the reasoning agent to review a consulting report.\n",
    "\n",
    "    Parameters:\n",
    "    report_text (str): The text of the consulting report to be reviewed.\n",
    "    history (list): A list of previous messages (optional). Default is an empty list.\n",
    "\n",
    "    Workflow:\n",
    "    1. The function creates a system message that sets the context for the reasoning agent.\n",
    "    2. It then creates a user message containing the consulting report text.\n",
    "    3. The function combines the system message, the history of previous messages, and the user message into a single list.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of message dictionaries, including the system message, any historical messages, and the user message.\n",
    "    \"\"\"\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an experienced IT strategy consultant. \"\n",
    "            \"You are reviewing a consulting report for completeness, clarity, risks, and alignment with best practices. \"\n",
    "            \"Think step-by-step and identify gaps, ask clarifying questions, or suggest improvements. \"\n",
    "            \"Your goal is to provide helpful, critical feedback using your expert knowledge.\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Here is the consulting report to review:\\n\\n{report_text}\"\n",
    "    }\n",
    "\n",
    "    return [system_msg] + history + [user_msg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track total tokens used and estimated cost\n",
    "total_tokens_used = 0\n",
    "estimated_cost_usd = 0.0\n",
    "\n",
    "# Cost per 1K tokens for GPT-3.5-turbo (adjust if using GPT-4)\n",
    "COST_PER_1K_TOKENS = 0.0015\n",
    "\n",
    "def call_openai_with_tracking(messages, model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=500):\n",
    "    \"\"\"\n",
    "    Calls OpenAI's ChatCompletion API with structured messages and tracks token usage and estimated cost.\n",
    "\n",
    "    Parameters:\n",
    "    messages (list): A list of message dictionaries, where each dictionary contains 'role' and 'content' keys.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "    max_tokens (int): The maximum number of tokens to generate in the completion. Default is 500.\n",
    "\n",
    "    Workflow:\n",
    "    1. The function takes the input parameters and calls the OpenAI ChatCompletion API.\n",
    "    2. The API returns a response containing multiple choices and token usage information.\n",
    "    3. The function extracts the content of the first choice from the response.\n",
    "    4. It updates the total tokens used and the estimated cost in USD.\n",
    "    5. It logs the prompt tokens, completion tokens, total tokens used so far, and the estimated cost.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the first choice from the API response.\n",
    "    \"\"\"\n",
    "    global total_tokens_used, estimated_cost_usd\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    usage = response['usage']\n",
    "    prompt_tokens = usage.get('prompt_tokens', 0)\n",
    "    completion_tokens = usage.get('completion_tokens', 0)\n",
    "    total = usage.get('total_tokens', prompt_tokens + completion_tokens)\n",
    "\n",
    "    # Update tracking\n",
    "    total_tokens_used += total\n",
    "    estimated_cost_usd += (total / 1000) * COST_PER_1K_TOKENS\n",
    "\n",
    "    # Logging\n",
    "    print(f\"🔢 Prompt: {prompt_tokens} tokens | Completion: {completion_tokens} tokens | Total so far: {total_tokens_used} tokens\")\n",
    "    print(f\"💰 Estimated cost so far: ${estimated_cost_usd:.4f} USD\")\n",
    "\n",
    "    return response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 Data Preprocessing Functions** <a id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the report into sections\n",
    "def split_report_into_sections(report_text):\n",
    "    \"\"\"\n",
    "    Splits a consulting report into sections based on headers.\n",
    "\n",
    "    Parameters:\n",
    "    report_text (str): The text of the consulting report to be split into sections.\n",
    "\n",
    "    Workflow:\n",
    "    1. The function initializes an empty dictionary to store sections and sets the current section to \"Header\".\n",
    "    2. It splits the report text into lines and iterates through each line.\n",
    "    3. For each line:\n",
    "       - If the line is blank, it skips to the next line.\n",
    "       - If the line ends with a colon and contains 4 or fewer words, it is considered a section header.\n",
    "         The current section is updated to this header (without the colon), and a new entry is created in the dictionary.\n",
    "       - Otherwise, the line is added to the current section's content.\n",
    "    4. After processing all lines, the function joins the content of each section into a single string.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "    \"\"\"\n",
    "    sections = {}\n",
    "    lines = report_text.strip().split(\"\\n\")\n",
    "    current_section = \"Header\"\n",
    "    sections[current_section] = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # skip blank lines\n",
    "        elif line.endswith(\":\") and len(line.split()) <= 4: # Check if it's a section header.  If yes, create a new section with the header as the key.\n",
    "            current_section = line.replace(\":\", \"\").strip()\n",
    "            sections[current_section] = []\n",
    "        else:\n",
    "            sections[current_section].append(line) # Add the line (contents below header) to the current section\n",
    "\n",
    "    # Join section contents with newlines\n",
    "    for key in sections:\n",
    "        sections[key] = \"\\n\".join(sections[key])\n",
    "\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 Static Reasoning Agent Functions** <a id=\"2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ITReportReviewer:\n",
    "    \"\"\"\n",
    "    A class to review sections of an IT consulting report using OpenAI's ChatCompletion API.\n",
    "\n",
    "    Process:\n",
    "    1. Initializes the reviewer with the report sections\n",
    "    2. Lets it review one section at a time using real reasoning\n",
    "    3. Stores and prints each review with feedback\n",
    "\n",
    "    Attributes:\n",
    "    sections (dict): A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "    review_history (list): A list to store the history of reviews for each section.\n",
    "\n",
    "    Methods:\n",
    "    review_section(section_name):\n",
    "        Reviews a specific section of the report using OpenAI's ChatCompletion API.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, report_sections, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
    "        \"\"\"\n",
    "        Initializes the ITReportReviewer with the given report sections, model, and temperature.\n",
    "\n",
    "        Parameters:\n",
    "        report_sections (dict): A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "        model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "        temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "        \"\"\"\n",
    "        self.sections = report_sections\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.review_history = []\n",
    "\n",
    "    def review_section(self, section_name):\n",
    "        \"\"\"\n",
    "        Reviews a specific section of the report using OpenAI's ChatCompletion API.\n",
    "\n",
    "        Parameters:\n",
    "        section_name (str): The name of the section to review.\n",
    "\n",
    "        Workflow:\n",
    "        1. Retrieves the text of the specified section from the sections dictionary.\n",
    "        2. If the section is empty or missing, prints a warning message.\n",
    "        3. Builds a prompt for reviewing the section using the build_review_prompt function.\n",
    "        4. Calls the OpenAI ChatCompletion API with tracking using the call_openai_with_tracking function.\n",
    "        5. Saves the review in the review_history attribute.\n",
    "        6. Prints the review for the specified section.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        section_text = self.sections.get(section_name, \"\")\n",
    "        if not section_text:\n",
    "            print(f\"⚠️ Section '{section_name}' is empty or missing.\")\n",
    "            return\n",
    "\n",
    "        # Build prompt for reviewing the section\n",
    "        messages = build_review_prompt(\n",
    "            report_text=f\"Section: {section_name}\\n\\n{section_text}\",\n",
    "            history=[]\n",
    "        )\n",
    "\n",
    "        # Get AI-generated reasoning using tracked OpenAI call\n",
    "        review = call_openai_with_tracking(messages, model=self.model, temperature=self.temperature)\n",
    "\n",
    "        # Save the review\n",
    "        self.review_history.append({\n",
    "            \"section\": section_name,\n",
    "            \"review\": review\n",
    "        })\n",
    "\n",
    "        print(f\"\\n✅ Review for section '{section_name}':\\n{review}\\n{'-'*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_full_review(agent):\n",
    "    # Combine all reviews into a single prompt\n",
    "    combined_review_text = \"\"\n",
    "    for step in agent.review_history:\n",
    "        combined_review_text += f\"Section: {step['section']}\\nFeedback: {step['review']}\\n\\n\"\n",
    "\n",
    "    # Build new prompt asking for a final report assessment\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an expert IT strategy consultant reviewing an internal report assessment. \"\n",
    "                \"Summarize the overall quality of the report based on the following section reviews. \"\n",
    "                \"Highlight gaps, strengths, and suggest next steps to improve the report.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": combined_review_text\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    summary = call_openai_with_tracking(messages)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4 ReAct Reasoning Agent Functions** <a id=\"2.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActConsultantAgent:\n",
    "    \"\"\"\n",
    "    A class to review sections of an IT consulting report using the ReAct (Reason + Act) framework with OpenAI's ChatCompletion API.\n",
    "\n",
    "    Process:\n",
    "    1. Initializes the agent with the section name and text.\n",
    "    2. Builds a prompt for the ReAct framework.\n",
    "    3. Tracks the history of thoughts, actions, and observations.\n",
    "\n",
    "    Attributes:\n",
    "    section_name (str): The name of the section to review.\n",
    "    section_text (str): The text of the section to review.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "    history (list): A list to store the history of thoughts, actions, and observations.\n",
    "\n",
    "    Methods:\n",
    "    build_react_prompt():\n",
    "        Builds a prompt for the ReAct framework based on the section text and history.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, section_name, section_text, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
    "        \"\"\"\n",
    "        Initializes the ReActConsultantAgent with the given section name, section text, model, and temperature.\n",
    "\n",
    "        Parameters:\n",
    "        section_name (str): The name of the section to review.\n",
    "        section_text (str): The text of the section to review.\n",
    "        model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "        temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "        \"\"\"\n",
    "        self.section_name = section_name\n",
    "        self.section_text = section_text\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.history = []\n",
    "        self.tool_usage = {}  # {action_name: count}\n",
    "        self.memory = {\n",
    "            \"section_notes\": {},     # {section_name: [insight1, insight2, ...]}\n",
    "            \"cross_section_flags\": [],  # [(sectionA, sectionB, observation)]\n",
    "            \"tool_history\": []       # [(step_number, action, section)]\n",
    "        }\n",
    "\n",
    "    def build_react_prompt(self):\n",
    "        \"\"\"\n",
    "        Builds a prompt for the ReAct framework based on the section text and history.\n",
    "\n",
    "        Workflow:\n",
    "        1. Constructs a base prompt with the section name and text.\n",
    "        2. Iterates through the history of thoughts, actions, and observations, appending them to the base prompt.\n",
    "        3. Adds a final line asking for the next thought and action.\n",
    "\n",
    "        Returns:\n",
    "        list: A list containing a single dictionary with the role 'user' and the constructed prompt as content.\n",
    "        \"\"\"\n",
    "        base_prompt = (\n",
    "            f\"You are an expert IT strategy consultant reviewing a report section titled '{self.section_name}'.\\n\"\n",
    "            \"You are using ReAct (Reason + Act) to think through the review.\\n\\n\"\n",
    "            \"Format each response like this:\\n\"\n",
    "            \"Thought: <your reasoning>\\n\"\n",
    "            \"Action: <one of: ask_question, flag_risk, recommend_fix, summarize>\\n\\n\"\n",
    "            f\"Here is the section content:\\n{self.section_text}\\n\\n\"\n",
    "        )\n",
    "\n",
    "        for step in self.history:\n",
    "            base_prompt += f\"Thought: {step['thought']}\\n\"\n",
    "            base_prompt += f\"Action: {step['action']}\\n\"\n",
    "            base_prompt += f\"Observation: {step['observation']}\\n\\n\"\n",
    "\n",
    "        base_prompt += \"What is your next Thought and Action?\"\n",
    "\n",
    "        return [{\"role\": \"user\", \"content\": base_prompt}]\n",
    "\n",
    "    def build_react_prompt_withTools(self):\n",
    "            \"\"\"\n",
    "            Builds a prompt for the ReAct framework based on the section text and history.\n",
    "\n",
    "            Workflow:\n",
    "            1. Constructs a base prompt with the section name and text.\n",
    "            2. Iterates through the history of thoughts, actions, and observations, appending them to the base prompt.\n",
    "            3. Adds a final line asking for the next thought and action.\n",
    "            For the check_guideline action, the prompt includes a placeholder for the topic.\n",
    "            LLM infers topic from the section_text\n",
    "\n",
    "            Returns:\n",
    "            list: A list containing a single dictionary with the role 'user' and the constructed prompt as content.\n",
    "            \"\"\"\n",
    "            base_prompt = (\n",
    "                f\"You are an expert IT strategy consultant reviewing a report section titled '{self.section_name}'.\\n\"\n",
    "                \"You are using ReAct (Reason + Act) to think through the review.\\n\\n\"\n",
    "                \"Format each response like this:\\n\"\n",
    "                \"Thought: <your reasoning>\\n\"\n",
    "                \"Action: <one of: \" + format_tools_list(tool_catalog) + \"'\\n\\n\"\n",
    "            )\n",
    "\n",
    "            base_prompt += format_tool_catalog_for_prompt(tool_catalog)\n",
    "            base_prompt += f\"Here is the section content:\\n{self.section_text}\\n\\n\"\n",
    "            \n",
    "            for step in self.history:\n",
    "                base_prompt += f\"Thought: {step['thought']}\\n\"\n",
    "                base_prompt += f\"Action: {step['action']}\\n\"\n",
    "                base_prompt += f\"Observation: {step['observation']}\\n\\n\"\n",
    "\n",
    "            base_prompt += \"What is your next Thought and Action?\"\n",
    "\n",
    "            return [{\"role\": \"user\", \"content\": base_prompt}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_react_loop_static(agent, max_steps=5):\n",
    "    \"\"\"\n",
    "    Runs the ReAct (Reason + Act) loop for a specified number of steps.\n",
    "\n",
    "    Purpose:\n",
    "    This function iterates through a reasoning and action loop using the ReAct framework to review a section of an IT consulting report. It generates thoughts, actions, and observations at each step, and stores the history of these steps.\n",
    "\n",
    "    Parameters:\n",
    "    agent (ReActConsultantAgent): An instance of the ReActConsultantAgent class, initialized with the section name and text.\n",
    "    max_steps (int): The maximum number of steps to run the loop. Default is 5.\n",
    "\n",
    "    Workflow:\n",
    "    1. Iterates through the loop for a maximum of `max_steps` times.\n",
    "    2. In each iteration:\n",
    "    - Calls `agent.build_react_prompt()` to construct the prompt for the ReAct framework.\n",
    "    - Calls `call_openai_with_tracking()` to get the response from the OpenAI API.\n",
    "    - Parses the response to extract the thought and action.\n",
    "    - Generates an observation based on the action.\n",
    "    - Stores the thought, action, and observation in the agent's history.\n",
    "    - Prints the result of the current step.\n",
    "    - Breaks the loop if the action is \"summarize\".\n",
    "    3. Returns the full reasoning history.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, where each dictionary contains the thought, action, and observation for each step.\n",
    "    \"\"\"\n",
    "    for step_num in range(max_steps):\n",
    "        messages = agent.build_react_prompt()\n",
    "        response = call_openai_with_tracking(messages, model=agent.model, temperature=agent.temperature)\n",
    "\n",
    "        # Parse response\n",
    "        try:\n",
    "            lines = response.strip().split(\"\\n\")\n",
    "            thought = next(line.split(\":\", 1)[1].strip() for line in lines if line.lower().startswith(\"thought\"))\n",
    "            action = next(line.split(\":\", 1)[1].strip() for line in lines if line.lower().startswith(\"action\"))\n",
    "        except:\n",
    "            print(\"⚠️ Failed to parse model response.\")\n",
    "            break\n",
    "\n",
    "        # Generate observation based on action\n",
    "        if action == \"ask_question\":\n",
    "            observation = \"Good question to ask the client for clarification.\"\n",
    "        elif action == \"flag_risk\":\n",
    "            observation = \"This is a legitimate risk that should be addressed.\"\n",
    "        elif action == \"recommend_fix\":\n",
    "            observation = \"The recommendation improves the section's clarity and compliance.\"\n",
    "        elif action == \"summarize\":\n",
    "            observation = \"Review complete.\"\n",
    "        else:\n",
    "            observation = \"Unrecognized action.\"\n",
    "\n",
    "        # Store step\n",
    "        agent.history.append({\n",
    "            \"thought\": thought,\n",
    "            \"action\": action,\n",
    "            \"observation\": observation\n",
    "        })\n",
    "\n",
    "        # Print result of this step\n",
    "        print(f\"\\n🔁 Step {step_num + 1}\")\n",
    "        print(f\"🧠 Thought: {thought}\")\n",
    "        print(f\"⚙️ Action: {action}\")\n",
    "        print(f\"👀 Observation: {observation}\")\n",
    "\n",
    "        if action == \"summarize\":\n",
    "            break\n",
    "\n",
    "    # Return full reasoning history\n",
    "    return agent.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_react_loop_check_withTool(agent, max_steps=5):\n",
    "    \"\"\"\n",
    "    Runs the ReAct (Reason + Act) loop for a specified number of steps.\n",
    "\n",
    "    Purpose:\n",
    "    This function iterates through a reasoning and action loop using the ReAct framework to review a section of an IT consulting report. It generates thoughts, actions, and observations at each step, and stores the history of these steps.\n",
    "\n",
    "    Parameters:\n",
    "    agent (ReActConsultantAgent): An instance of the ReActConsultantAgent class, initialized with the section name and text.\n",
    "    max_steps (int): The maximum number of steps to run the loop. Default is 5.\n",
    "\n",
    "    Workflow:\n",
    "    1. Iterates through the loop for a maximum of `max_steps` times.\n",
    "    2. In each iteration:\n",
    "       - Calls `agent.build_react_prompt()` to construct the prompt for the ReAct framework.\n",
    "       - Calls `call_openai_with_tracking()` to get the response from the OpenAI API.\n",
    "       - Parses the response to extract the thought and action.\n",
    "       - Generates an observation based on the action.\n",
    "       - Stores the thought, action, and observation in the agent's history.\n",
    "       - Prints the result of the current step.\n",
    "       - Breaks the loop if the action is \"summarize\".\n",
    "    3. Returns the full reasoning history.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, where each dictionary contains the thought, action, and observation for each step.\n",
    "    \"\"\"\n",
    "    for step_num in range(max_steps):\n",
    "        messages = agent.build_react_prompt_withTools()\n",
    "        response = call_openai_with_tracking(messages, model=agent.model, temperature=agent.temperature)\n",
    "\n",
    "        # Parse response\n",
    "        try:\n",
    "            lines = response.strip().split(\"\\n\")\n",
    "            thought = next(line.split(\":\", 1)[1].strip() for line in lines if line.lower().startswith(\"thought\"))\n",
    "            action = next(line.split(\":\", 1)[1].strip() for line in lines if line.lower().startswith(\"action\"))\n",
    "            # Log tool usage\n",
    "            if hasattr(agent, \"tool_usage\"):\n",
    "                agent.tool_usage[action] = agent.tool_usage.get(action, 0) + 1\n",
    "        except:\n",
    "            print(\"⚠️ Failed to parse model response.\")\n",
    "            break\n",
    "\n",
    "        # Generate observation based on action\n",
    "        if action.startswith(\"check_guideline\"): # tool #1: check_guideline\n",
    "            match = re.match(r'check_guideline\\[\"(.+?)\"\\]', action)\n",
    "            if match:\n",
    "                topic = match.group(1)\n",
    "                observation = check_guideline(topic)\n",
    "            else:\n",
    "                print(\"⚠️ Could not parse check_guideline action.\")\n",
    "        elif action.startswith(\"keyword_match_in_section\"): # tool #2: keyword_match_in_section\n",
    "                match = re.match(r'keyword_match_in_section\\[\"(.+?)\"\\]', action)\n",
    "                if match:\n",
    "                    term = match.group(1)\n",
    "                    observation = keyword_match_in_section(term, agent.section_text)\n",
    "                else:\n",
    "                    print(\"⚠️ Could not parse keyword_match_in_section action.\")\n",
    "        elif action.startswith(\"check_timeline_feasibility\"): # tool #3: check_timeline_feasibility\n",
    "            try:\n",
    "                duration = action.split(\"[\", 1)[1].rstrip(\"]\").strip('\"')\n",
    "                observation = check_timeline_feasibility(duration)\n",
    "            except:\n",
    "                observation = \"⚠️ Could not parse check_timeline_feasibility action.\"\n",
    "        elif action.startswith(\"search_report\"): # tool #4: search_report\n",
    "            match = re.match(r'search_report\\[\"(.+?)\"\\]', action)\n",
    "            if match:\n",
    "                term = match.group(1)\n",
    "                observation = search_report(term, report_sections)\n",
    "            else:\n",
    "                observation = \"⚠️ Could not parse search_report action.\"\n",
    "        elif action.startswith(\"search_web\"):\n",
    "            match = re.match(r'search_web\\[\"(.+?)\"\\]', action)\n",
    "            if match:\n",
    "                query = match.group(1)\n",
    "                observation = search_web(query)\n",
    "            else:\n",
    "                observation = \"⚠️ Could not parse search_web action.\"\n",
    "        elif action == \"check_for_jargon\":\n",
    "            observation = check_for_jargon(agent.section_text)\n",
    "        elif action == \"generate_client_questions\":\n",
    "            observation = generate_client_questions(agent.section_text)\n",
    "        elif action == \"highlight_missing_sections\":\n",
    "            observation = highlight_missing_sections(report_sections)\n",
    "        elif action.startswith(\"check_alignment_with_goals\"):\n",
    "            match = re.match(r'check_alignment_with_goals\\[\"(.+?)\"\\]', action)\n",
    "            if match:\n",
    "                sec_name = match.group(1)\n",
    "                observation = check_alignment_with_goals(sec_name, report_sections)\n",
    "            else:\n",
    "                observation = \"⚠️ Could not parse check_alignment_with_goals action.\"\n",
    "        elif action.startswith(\"compare_with_other_section\"):\n",
    "            match = re.match(r'compare_with_other_section\\[\"(.+?)\",\\s*\"(.+?)\"\\]', action)\n",
    "            if match:\n",
    "                section_a = match.group(1)\n",
    "                section_b = match.group(2)\n",
    "                observation = compare_with_other_section(section_a, section_b, report_sections)\n",
    "            else:\n",
    "                observation = \"⚠️ Could not parse compare_with_other_section action.\"\n",
    "        elif action == \"ask_question\": # hardcoded action\n",
    "            observation = \"Good question to ask the client for clarification.\"\n",
    "        elif action == \"flag_risk\": # hardcoded action\n",
    "            observation = \"This is a legitimate risk that should be addressed.\"\n",
    "        elif action == \"recommend_fix\": # hardcoded action \n",
    "            observation = \"The recommendation improves the section's clarity and compliance.\"\n",
    "        elif action == \"summarize\": # hardcoded action; end the loop\n",
    "            observation = \"Review complete.\"\n",
    "        elif action == \"tool_help\":\n",
    "            observation = format_tool_catalog_for_prompt(tool_catalog)\n",
    "        elif action.startswith(\"suggest_tool_for\"):\n",
    "            match = re.match(r'suggest_tool_for\\[\"(.+?)\"\\]', action) # Extract the goal from the action\n",
    "            if match:\n",
    "                goal = match.group(1)\n",
    "                matches = pick_tool_by_intent_fuzzy(goal, tool_catalog)\n",
    "                if matches:\n",
    "                    observation = \"Best match based on your goal:\\n\" + \"\\n\".join(\n",
    "                        [f\"{tool} (match: {score})\" for tool, score in matches]\n",
    "                    )\n",
    "                else:\n",
    "                    observation = \"⚠️ No matching tool found. Showing available tools:\\n\" + format_tool_catalog_for_prompt(tool_catalog)\n",
    "            else:\n",
    "                observation = \"⚠️ Could not parse suggest_tool_for action.\"\n",
    "        elif action == \"final_summary\":\n",
    "            observation = generate_final_summary(agent)\n",
    "        else:\n",
    "            observation = \"Unrecognized action.\"\n",
    "        \n",
    "        # update agent memory \n",
    "        # Track tool history\n",
    "        agent.memory[\"tool_history\"].append((step_num, action, agent.section_name))\n",
    "\n",
    "        # If observation is useful, store in section memory\n",
    "        if action not in {\"summarize\", \"tool_help\", \"suggest_tool_for\"}:\n",
    "            agent.memory[\"section_notes\"].setdefault(agent.section_name, []).append(observation)\n",
    "\n",
    "        # Special case for section comparisons\n",
    "        if action.startswith(\"compare_with_other_section\"):\n",
    "            match = re.match(r'compare_with_other_section\\[\"(.+?)\",\\s*\"(.+?)\"\\]', action)\n",
    "            if match:\n",
    "                sectionA, sectionB = match.groups()\n",
    "                agent.memory[\"cross_section_flags\"].append((sectionA, sectionB, observation))\n",
    "\n",
    "        # Store step\n",
    "        agent.history.append({\n",
    "            \"thought\": thought,\n",
    "            \"action\": action,\n",
    "            \"observation\": observation\n",
    "        })\n",
    "\n",
    "        # Print result of this step\n",
    "        print(f\"\\n🔁 Step {step_num + 1}\")\n",
    "        print(f\"🧠 Thought: {thought}\")\n",
    "        print(f\"⚙️ Action: {action}\")\n",
    "        print(f\"👀 Observation: {observation}\")\n",
    "\n",
    "        if action == \"summarize\":\n",
    "            break\n",
    "\n",
    "    # Return full reasoning history\n",
    "    return agent.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dicionary of tools available for ReActConsultantAgent to call\n",
    "\n",
    "tool_catalog = {\n",
    "    \"check_guideline\": {\n",
    "        \"description\": \"Look up a best practice for a given topic\",\n",
    "        \"usage\": 'check_guideline[\"cloud security\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\n",
    "            \"check_guideline[\\\"data governance\\\"]\",\n",
    "            \"check_guideline[\\\"migration strategy\\\"]\"\n",
    "        ]\n",
    "    },\n",
    "    \"keyword_match_in_section\": {\n",
    "        \"description\": \"Check if a keyword appears in the current section\",\n",
    "        \"usage\": 'keyword_match_in_section[\"encryption\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\n",
    "            \"keyword_match_in_section[\\\"stakeholders\\\"]\"\n",
    "        ]\n",
    "    },\n",
    "    \"check_timeline_feasibility\": {\n",
    "        \"description\": \"Check if a project timeline is realistic for migration\",\n",
    "        \"usage\": 'check_timeline_feasibility[\"12 weeks\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\n",
    "            \"check_timeline_feasibility[\\\"3 months\\\"]\"\n",
    "        ]\n",
    "    },\n",
    "    \"search_report\": {\n",
    "        \"description\": \"Search the entire report for a concept or term\",\n",
    "        \"usage\": 'search_report[\"data governance\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\n",
    "            \"search_report[\\\"Zero Trust\\\"]\"\n",
    "        ]\n",
    "    },\n",
    "    \"ask_question\": {\n",
    "        \"description\": \"Ask a clarifying question about the report\",\n",
    "        \"usage\": \"ask_question\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"ask_question\"]\n",
    "    },\n",
    "    \"flag_risk\": {\n",
    "        \"description\": \"Flag a gap, issue, or concern in the section\",\n",
    "        \"usage\": \"flag_risk\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"flag_risk\"]\n",
    "    },\n",
    "    \"recommend_fix\": {\n",
    "        \"description\": \"Suggest a specific improvement\",\n",
    "        \"usage\": \"recommend_fix\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"recommend_fix\"]\n",
    "    },\n",
    "    \"summarize\": {\n",
    "        \"description\": \"Summarize your review and end the loop\",\n",
    "        \"usage\": \"summarize\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"summarize\"]\n",
    "    },\n",
    "    \"tool_help\": {\n",
    "        \"description\": \"View descriptions, usage, and examples for available tools\",\n",
    "        \"usage\": \"tool_help\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"tool_help\"]\n",
    "    },\n",
    "    \"suggest_tool_for\": {\n",
    "        \"description\": \"Ask which tool best supports a particular goal or intent\",\n",
    "        \"usage\": 'suggest_tool_for[\"goal or intent\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\n",
    "            'suggest_tool_for[\"check if encryption is included\"]',\n",
    "            'suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]'\n",
    "        ]\n",
    "    }, \n",
    "    \"search_web\": {\n",
    "        \"description\": \"Look up a concept, framework, or term on the web (DuckDuckGo)\",\n",
    "        \"usage\": 'search_web[\"Zero Trust model\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": ['search_web[\"data mesh\"]']\n",
    "    },\n",
    "    \"check_for_jargon\": {\n",
    "        \"description\": \"Identify jargon or overly technical terms that may need simplification\",\n",
    "        \"usage\": \"check_for_jargon\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"check_for_jargon\"]\n",
    "    },\n",
    "    \"generate_client_questions\": {\n",
    "        \"description\": \"Generate clarifying or skeptical questions a client might ask about the section\",\n",
    "        \"usage\": \"generate_client_questions\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"generate_client_questions\"]\n",
    "    },\n",
    "    \"highlight_missing_sections\": {\n",
    "        \"description\": \"Identify which expected sections are missing from the report\",\n",
    "        \"usage\": \"highlight_missing_sections\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"highlight_missing_sections\"]\n",
    "    },\n",
    "    \"check_alignment_with_goals\": {\n",
    "        \"description\": \"Evaluate how well a report section aligns with the stated goals\",\n",
    "        \"usage\": 'check_alignment_with_goals[\"section_name\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": ['check_alignment_with_goals[\"Key Recommendations\"]']\n",
    "    },\n",
    "    \"compare_with_other_section\": {\n",
    "        \"description\": \"Compare two sections to identify overlaps, contradictions, or gaps\",\n",
    "        \"usage\": 'compare_with_other_section[\"sectionA\", \"sectionB\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\n",
    "            'compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]',\n",
    "            'compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]'\n",
    "        ]\n",
    "    },\n",
    "    \"final_summary\": {\n",
    "        \"description\": \"Generate a final client-facing summary based on insights gathered across all sections\",\n",
    "        \"usage\": \"final_summary\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"final_summary\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the tool catalog for display in the prompt for consumption by LLM\n",
    "\n",
    "def format_tool_catalog_for_prompt(tool_catalog):\n",
    "    \"\"\"\n",
    "    Formats the tool catalog for display in the prompt for consumption by LLM.\n",
    "\n",
    "    Purpose:\n",
    "    This function formats the tool catalog into a human-readable string that lists each tool along with its description and usage. This formatted string can be used in prompts for language models to understand the available tools.\n",
    "\n",
    "    Parameters:\n",
    "    tool_catalog (dict): A dictionary where keys are tool names and values are dictionaries containing tool metadata, including 'description' and 'usage'.\n",
    "\n",
    "    Workflow:\n",
    "    1. Initializes a list with the header \"Available tools:\".\n",
    "    2. Iterates through each tool in the tool_catalog dictionary.\n",
    "    3. For each tool, appends its name, description, and usage to the list.\n",
    "    4. Joins the list into a single string with newline characters.\n",
    "\n",
    "    Returns:\n",
    "    str: A formatted string listing all tools with their descriptions and usage.\n",
    "    \"\"\"\n",
    "    lines = [\"Available tools:\\n\"]\n",
    "    for tool, meta in tool_catalog.items():\n",
    "        lines.append(f\"- {tool} (v{meta['version']}): {meta['description']}\")\n",
    "        lines.append(f\"  Usage: {meta['usage']}\")\n",
    "        if meta.get(\"examples\"):\n",
    "            for ex in meta[\"examples\"]:\n",
    "                lines.append(f\"  Example: {ex}\")\n",
    "        lines.append(\"\")  # spacing between tools\n",
    "    return \"\\n\".join(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\n"
     ]
    }
   ],
   "source": [
    "def format_tools_list(tool_catalog):\n",
    "    \"\"\"\n",
    "    Formats the list of tools from the tool_catalog dictionary as a comma-separated string.\n",
    "\n",
    "    Parameters:\n",
    "    tool_catalog (dict): A dictionary where keys are tool names and values are dictionaries containing tool metadata.\n",
    "\n",
    "    Returns:\n",
    "    str: A comma-separated string of tool names.\n",
    "    \"\"\"\n",
    "    tools_list = \", \".join(tool_catalog.keys())\n",
    "    return tools_list\n",
    "\n",
    "# Example usage\n",
    "formatted_tools = format_tools_list(tool_catalog)\n",
    "print(formatted_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool #1: Check for best practices in a given section\n",
    "\n",
    "# Simulated best practices reference data\n",
    "best_practices = {\n",
    "    \"cloud security\": \"Follow NIST Cybersecurity Framework. Include access control, encryption at rest/in-transit, and regular audits.\",\n",
    "    \"data governance\": \"Establish data stewards, quality standards, lifecycle rules, and metadata documentation.\",\n",
    "    \"migration\": \"Use phased migration, sandbox testing, rollback planning, and stakeholder communication.\"\n",
    "}\n",
    "\n",
    "def check_guideline(topic):\n",
    "    \"\"\"\n",
    "    Checks for best practices related to a given topic.\n",
    "\n",
    "    Purpose:\n",
    "    This function looks up best practices for a specified topic from a predefined dictionary of best practices.\n",
    "\n",
    "    Parameters:\n",
    "    topic (str): The topic for which best practices are to be checked.\n",
    "\n",
    "    Workflow:\n",
    "    1. The function converts the topic to lowercase to ensure case-insensitive matching.\n",
    "    2. It looks up the topic in the `best_practices` dictionary.\n",
    "    3. If a matching guideline is found, it returns the guideline.\n",
    "    4. If no matching guideline is found, it returns a message indicating that no matching guideline was found.\n",
    "\n",
    "    Returns:\n",
    "    str: The best practice guideline for the specified topic, or a message indicating no matching guideline was found.\n",
    "    \"\"\"\n",
    "    return best_practices.get(topic.lower(), \"No matching guideline found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool #2: Keyword matching in a section\n",
    "# This tool helps the agent check if a keyword or concept is explicitly mentioned in the section.\n",
    "# This is great for validating whether the report includes key elements (e.g., \"encryption\", \"stakeholders\", \"Zero Trust\").  \n",
    "\n",
    "def keyword_match_in_section(term, section_text):\n",
    "    \"\"\"\n",
    "    Checks if a keyword or concept is explicitly mentioned in a section of the report.\n",
    "\n",
    "    Purpose:\n",
    "    This function helps validate whether the report includes key elements by checking if a specified keyword or concept is mentioned in the section text.\n",
    "\n",
    "    Parameters:\n",
    "    term (str): The keyword or concept to search for in the section.\n",
    "    section_text (str): The text of the section to search within.\n",
    "\n",
    "    Workflow:\n",
    "    1. Converts the keyword and section text to lowercase to ensure case-insensitive matching.\n",
    "    2. Checks if the keyword is present in the section text.\n",
    "    3. Returns a message indicating whether the keyword was found or not.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating whether the keyword was found in the section.\n",
    "    \"\"\"\n",
    "    term_lower = term.lower()\n",
    "    if term_lower in section_text.lower():\n",
    "        return f\"The keyword '{term}' was found in the section.\"\n",
    "    else:\n",
    "        return f\"The keyword '{term}' was NOT found in the section.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool #3: Check feasibility of timeline for IT migration\n",
    "# This tool helps the agent assess the feasibility of a timeline for an IT migration project.\n",
    "# It checks if the timeline is too short, potentially feasible, or reasonable for a full migration.\n",
    "\n",
    "def check_timeline_feasibility(duration_str):\n",
    "    \"\"\"\n",
    "    Checks the feasibility of a timeline for an IT migration project.\n",
    "\n",
    "    Purpose:\n",
    "    This function helps assess whether a given timeline for an IT migration project is too short, potentially feasible, or reasonable.\n",
    "\n",
    "    Parameters:\n",
    "    duration_str (str): The timeline duration as a string (e.g., \"6-12 months\", \"8 to 10 weeks\", \"a few months\").\n",
    "\n",
    "    Workflow:\n",
    "    1. Converts the duration string to lowercase and strips any leading/trailing whitespace.\n",
    "    2. Initializes a dictionary of fuzzy terms (e.g., \"a few\", \"several\") with their estimated numeric values.\n",
    "    3. Checks if the duration string contains any fuzzy terms and estimates the duration in months.\n",
    "    4. If no fuzzy terms are found, checks for ranges (e.g., \"6-12 months\") or single values (e.g., \"6 months\") and calculates the average duration in months.\n",
    "    5. If the duration cannot be parsed, returns a warning message.\n",
    "    6. Evaluates the feasibility of the timeline based on the calculated duration in months:\n",
    "       - If less than 3 months, returns that the timeline is likely too short.\n",
    "       - If between 3 and 12 months, returns that the timeline is potentially feasible.\n",
    "       - If more than 12 months, returns that the timeline seems reasonable.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating the feasibility of the timeline.\n",
    "    \"\"\"\n",
    "    duration_str = duration_str.lower().strip()\n",
    "\n",
    "    fuzzy_terms = {\n",
    "        \"a few\": 3,\n",
    "        \"a couple\": 2,\n",
    "        \"several\": 6,\n",
    "        \"some\": 4,\n",
    "        \"many\": 9,\n",
    "        \"a handful\": 5\n",
    "    }\n",
    "\n",
    "    months = None\n",
    "\n",
    "    # Check for fuzzy terms like \"a few months\"\n",
    "    for fuzzy_word, estimated_num in fuzzy_terms.items():\n",
    "        if fuzzy_word in duration_str:\n",
    "            if \"week\" in duration_str:\n",
    "                months = estimated_num / 4\n",
    "            elif \"month\" in duration_str:\n",
    "                months = estimated_num\n",
    "            break\n",
    "\n",
    "    # Check for ranges like \"6-12 months\" or \"8 to 10 weeks\"\n",
    "    if months is None:\n",
    "        range_match = re.match(r'(\\d+)\\s*[-to]+\\s*(\\d+)\\s*(weeks|months)', duration_str)\n",
    "        single_match = re.match(r'(\\d+)\\s*(weeks|months)', duration_str)\n",
    "\n",
    "        try:\n",
    "            if range_match:\n",
    "                start = int(range_match.group(1))\n",
    "                end = int(range_match.group(2))\n",
    "                unit = range_match.group(3)\n",
    "                avg = (start + end) / 2\n",
    "                months = avg / 4 if \"week\" in unit else avg\n",
    "\n",
    "            elif single_match:\n",
    "                num = int(single_match.group(1))\n",
    "                unit = single_match.group(2)\n",
    "                months = num / 4 if \"week\" in unit else num\n",
    "        except:\n",
    "            return \"⚠️ Could not parse timeline value.\"\n",
    "\n",
    "    if months is None:\n",
    "        return \"⚠️ Could not understand the timeline. Use phrases like '6 months', '8-12 weeks', or 'a few months'.\"\n",
    "\n",
    "    # Evaluate the feasibility\n",
    "    if months < 3:\n",
    "        return f\"The timeline ({duration_str}) is likely too short for a full migration.\"\n",
    "    elif 3 <= months <= 12:\n",
    "        return f\"The timeline ({duration_str}) is potentially feasible depending on complexity.\"\n",
    "    else:\n",
    "        return f\"The timeline ({duration_str}) seems reasonable for a full IT migration.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool #4: Search for a term in the entire report\n",
    "# This tool helps the agent search for a specific term in the entire consulting report.\n",
    "# It returns the sections where the term was found, if any.\n",
    "\n",
    "def search_report(term, report_sections):\n",
    "    \"\"\"\n",
    "    Searches for a specific term in the entire consulting report.\n",
    "\n",
    "    Purpose:\n",
    "    This function helps the agent search for a specific term in the entire consulting report and returns the sections where the term was found, if any.\n",
    "\n",
    "    Parameters:\n",
    "    term (str): The term to search for in the report.\n",
    "    report_sections (dict): A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "\n",
    "    Workflow:\n",
    "    1. Initializes an empty list `found_in` to store the sections where the term is found.\n",
    "    2. Iterates through each section in the `report_sections` dictionary.\n",
    "    3. For each section, checks if the term (case-insensitive) is present in the section content.\n",
    "    4. If the term is found, appends the section header to the `found_in` list.\n",
    "    5. After checking all sections, returns a message indicating the sections where the term was found or a message indicating that the term was not found.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating the sections where the term was found or a message indicating that the term was not found.\n",
    "    \"\"\"\n",
    "    found_in = []\n",
    "    for section, content in report_sections.items():\n",
    "        if term.lower() in content.lower():\n",
    "            found_in.append(section)\n",
    "    if found_in:\n",
    "        return f\"The term '{term}' was found in: {', '.join(found_in)}.\"\n",
    "    else:\n",
    "        return f\"The term '{term}' was NOT found anywhere in the report.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool picker: Pick tools based on intent description\n",
    "# This function picks tools from the tool catalog based on the intent description.\n",
    "# It searches through the tool catalog and returns a list of tools whose descriptions match the given intent description.\n",
    "\n",
    "def pick_tool_by_intent(intent_description, tool_catalog):\n",
    "    \"\"\"\n",
    "    Picks tools from the tool catalog based on the intent description.\n",
    "\n",
    "    Purpose:\n",
    "    This function searches through the tool catalog and returns a list of tools whose descriptions match the given intent description.\n",
    "\n",
    "    Parameters:\n",
    "    intent_description (str): A description of the intent to match against tool descriptions.\n",
    "    tool_catalog (dict): A dictionary where keys are tool names and values are dictionaries containing tool metadata, including 'description'.\n",
    "\n",
    "    Workflow:\n",
    "    1. Initializes an empty list `matches` to store the names of matching tools.\n",
    "    2. Iterates through each tool in the `tool_catalog` dictionary.\n",
    "    3. For each tool, checks if the `intent_description` is present in the tool's description (case-insensitive).\n",
    "    4. If a match is found, appends the tool name to the `matches` list.\n",
    "    5. Returns the list of matching tools.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tool names whose descriptions match the given intent description.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    for tool, meta in tool_catalog.items():\n",
    "        if intent_description.lower() in meta[\"description\"].lower():\n",
    "            matches.append(tool)\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool picker: Pick tools based on fuzzy intent description matching\n",
    "# This function picks tools from the tool catalog based on a fuzzy intent description matching.\n",
    "# It uses fuzzy string matching to find tools whose descriptions closely match the given intent description.\n",
    "\n",
    "def pick_tool_by_intent_fuzzy(intent_description, tool_catalog, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Picks tools from the tool catalog based on a fuzzy intent description matching.\n",
    "\n",
    "    Purpose:\n",
    "    This function uses fuzzy string matching to find tools whose descriptions closely match the given intent description.\n",
    "\n",
    "    Parameters:\n",
    "    intent_description (str): A description of the intent to match against tool descriptions.\n",
    "    tool_catalog (dict): A dictionary where keys are tool names and values are dictionaries containing tool metadata, including 'description'.\n",
    "    threshold (float): The minimum similarity ratio (between 0 and 1) to consider a match. Default is 0.3.\n",
    "\n",
    "    Workflow:\n",
    "    1. Initializes an empty list `matches` to store the names and similarity ratios of matching tools.\n",
    "    2. Iterates through each tool in the `tool_catalog` dictionary.\n",
    "    3. For each tool, calculates the similarity ratio between the `intent_description` and the tool's description using `SequenceMatcher`.\n",
    "    4. If the similarity ratio exceeds the `threshold`, appends the tool name and ratio to the `matches` list.\n",
    "    5. Sorts the `matches` list by similarity ratio in descending order.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tuples, where each tuple contains a tool name and its similarity ratio, sorted by best match.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    for tool, meta in tool_catalog.items():\n",
    "        ratio = SequenceMatcher(None, intent_description.lower(), meta[\"description\"].lower()).ratio()\n",
    "        if ratio > threshold:\n",
    "            matches.append((tool, round(ratio, 2)))\n",
    "    return sorted(matches, key=lambda x: -x[1])  # sort by best match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tool usage summary\n",
    "\n",
    "def print_tool_usage(agent):\n",
    "    \"\"\"\n",
    "    Prints a summary of tool usage by the ReActConsultantAgent.\n",
    "\n",
    "    Purpose:\n",
    "    This function provides a summary of how many times each tool was used by the ReActConsultantAgent during the review process.\n",
    "\n",
    "    Parameters:\n",
    "    agent (ReActConsultantAgent): An instance of the ReActConsultantAgent class, which contains the tool usage data.\n",
    "\n",
    "    Workflow:\n",
    "    1. Prints a header \"Tool Usage Summary\".\n",
    "    2. Iterates through the `tool_usage` dictionary of the agent, sorted by usage count in descending order.\n",
    "    3. Prints the name of each tool and the number of times it was used.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"\\n📊 Tool Usage Summary:\")\n",
    "    for tool, count in sorted(agent.tool_usage.items(), key=lambda x: -x[1]):\n",
    "        print(f\"- {tool}: {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tool usage summary\n",
    "def plot_tool_usage(tool_usage_dict, title=\"Tool Usage Summary\"):\n",
    "    \"\"\"\n",
    "    Plots a horizontal bar chart summarizing the usage of various tools.\n",
    "\n",
    "    Purpose:\n",
    "    This function visualizes the usage count of different tools in a horizontal bar chart, making it easy to see which tools were used most frequently.\n",
    "\n",
    "    Parameters:\n",
    "    tool_usage_dict (dict): A dictionary where keys are tool names and values are their respective usage counts.\n",
    "    title (str): The title of the plot. Default is \"Tool Usage Summary\".\n",
    "\n",
    "    Workflow:\n",
    "    1. Extracts the tool names and their usage counts from the tool_usage_dict.\n",
    "    2. Creates a horizontal bar chart using matplotlib.\n",
    "    3. Adds usage counts as text labels on the bars.\n",
    "    4. Inverts the y-axis to display the highest count at the top.\n",
    "    5. Adjusts the layout for better visualization and displays the plot.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    tools = list(tool_usage_dict.keys())\n",
    "    counts = list(tool_usage_dict.values())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.barh(tools, counts)\n",
    "    plt.xlabel(\"Usage Count\")\n",
    "    plt.title(title)\n",
    "\n",
    "    # Add counts on the bars\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 0.2, bar.get_y() + bar.get_height()/2, str(int(width)), va='center')\n",
    "\n",
    "    plt.gca().invert_yaxis()  # Highest count at top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to search the web for relevant information\n",
    "\n",
    "def search_web(query, max_results=1):\n",
    "    \"\"\"\n",
    "    Searches the web for relevant information using DuckDuckGo.\n",
    "\n",
    "    Purpose:\n",
    "    This function uses the DuckDuckGo search engine to find relevant information based on a given query. It returns the snippet of the first search result.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The search query to find relevant information.\n",
    "    max_results (int): The maximum number of search results to retrieve. Default is 1.\n",
    "\n",
    "    Workflow:\n",
    "    1. Initializes a DuckDuckGo search session using DDGS.\n",
    "    2. Performs a text search with the given query and retrieves up to `max_results` results.\n",
    "    3. Iterates through the search results and returns the snippet of the first result.\n",
    "    4. If no results are found, returns a message indicating no relevant results were found.\n",
    "    5. If an exception occurs during the search, returns a message indicating the web search failed along with the exception message.\n",
    "\n",
    "    Returns:\n",
    "    str: The snippet of the first search result, or a message indicating no relevant results were found or the web search failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = ddgs.text(query, max_results=max_results)\n",
    "            for r in results:\n",
    "                return r[\"body\"]  # return the first result's snippet\n",
    "        return \"No relevant results found.\"\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Web search failed: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to check for jargon or technical terms in a section\n",
    "\n",
    "JARGON_LIST = {\n",
    "    \"synergy\", \"leverage\", \"optimize\", \"stakeholder alignment\", \"enablement\",\n",
    "    \"digital transformation\", \"bandwidth\", \"scalability\", \"paradigm\",\n",
    "    \"blockchain\", \"AI\", \"ML\", \"IoT\", \"Zero Trust\", \"DevOps\", \"infrastructure-as-code\",\n",
    "    \"EHR\", \"CRM\", \"VPN\", \"cloud-native\", \"containerization\", \"agile methodology\"\n",
    "}\n",
    "\n",
    "def check_for_jargon(section_text):\n",
    "    \"\"\"\n",
    "    Checks for jargon or technical terms in a section of the report.\n",
    "\n",
    "    Purpose:\n",
    "    This function helps identify the presence of jargon or technical terms in a section of the report by searching for predefined terms.\n",
    "\n",
    "    Parameters:\n",
    "    section_text (str): The text of the section to search within.\n",
    "\n",
    "    Workflow:\n",
    "    1. Initializes an empty list `found_terms` to store the jargon or technical terms found in the section.\n",
    "    2. Iterates through each term in the `JARGON_LIST` set.\n",
    "    3. For each term, constructs a regex pattern to match the term as a whole word (case-insensitive).\n",
    "    4. Searches for the term in the section text using the regex pattern.\n",
    "    5. If the term is found, appends it to the `found_terms` list.\n",
    "    6. After checking all terms, returns a message indicating the jargon or technical terms found or a message indicating that no notable jargon or technical terms were found.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating the jargon or technical terms found in the section, or a message indicating that no notable jargon or technical terms were found.\n",
    "    \"\"\"\n",
    "    found_terms = []\n",
    "    for term in JARGON_LIST:\n",
    "        pattern = r\"\\b\" + re.escape(term) + r\"\\b\"\n",
    "        if re.search(pattern, section_text, flags=re.IGNORECASE):\n",
    "            found_terms.append(term)\n",
    "    if found_terms:\n",
    "        return f\"The section includes jargon or technical terms: {', '.join(found_terms)}.\"\n",
    "    else:\n",
    "        return \"No notable jargon or technical terms found.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to generate client questions based on a section of a report\n",
    "def generate_client_questions(section_text, model=\"gpt-3.5-turbo\", temperature=0.6):\n",
    "    \"\"\"\n",
    "    Generates client questions based on a section of an IT strategy report.\n",
    "\n",
    "    Purpose:\n",
    "    This function acts as a skeptical client reviewing a section of an IT strategy report and generates 3-5 clarifying or challenging questions based on potential assumptions, unclear terms, or missing context.\n",
    "\n",
    "    Parameters:\n",
    "    section_text (str): The text of the section to generate questions for.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.6.\n",
    "\n",
    "    Workflow:\n",
    "    1. Constructs a prompt that instructs the model to act as a skeptical client and generate questions based on the section text.\n",
    "    2. Creates a list of messages with the constructed prompt.\n",
    "    3. Calls the OpenAI API with tracking using the call_openai_with_tracking function.\n",
    "    4. If the API call is successful, returns the generated questions.\n",
    "    5. If an exception occurs, returns a failure message with the exception details.\n",
    "\n",
    "    Returns:\n",
    "    str: The generated questions or a failure message if the API call fails.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are acting as a skeptical client reviewing the following section of an IT strategy report.\\n\"\n",
    "        \"Generate 3-5 clarifying or challenging questions the client might ask based on potential assumptions, unclear terms, or missing context.\\n\\n\"\n",
    "        f\"Section:\\n{section_text}\\n\\n\"\n",
    "        \"Questions:\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    try:\n",
    "        response = call_openai_with_tracking(messages, model=model, temperature=temperature)\n",
    "        return response.strip()\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Failed to generate questions: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to check report has expected sections\n",
    "# can tailor expected sections list as needed\n",
    "\n",
    "EXPECTED_SECTIONS = {\n",
    "    \"Executive Summary\",\n",
    "    \"Goals & Objectives\",\n",
    "    \"Current State Assessment\",\n",
    "    \"Gap Analysis\",\n",
    "    \"Future State Vision\",\n",
    "    \"Roadmap & Timeline\",\n",
    "    \"Technology Architecture\",\n",
    "    \"Data & Analytics Strategy\",\n",
    "    \"Security & Privacy\",\n",
    "    \"Change Management Plan\",\n",
    "    \"Risks & Mitigations\",\n",
    "    \"Key Recommendations\"\n",
    "}\n",
    "\n",
    "def highlight_missing_sections(report_sections_dict):\n",
    "    \"\"\"\n",
    "    Highlights missing sections in the consulting report based on expected sections.\n",
    "\n",
    "    Purpose:\n",
    "    This function checks the provided report sections against a predefined set of expected sections and identifies any missing sections.\n",
    "\n",
    "    Parameters:\n",
    "    report_sections_dict (dict): A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "\n",
    "    Workflow:\n",
    "    1. Converts the keys of the provided report sections dictionary to a set.\n",
    "    2. Calculates the difference between the expected sections and the found sections.\n",
    "    3. If there are missing sections, returns a message listing the missing sections.\n",
    "    4. If all expected sections are present, returns a message indicating that all sections are present.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating the missing sections or confirming that all expected sections are present.\n",
    "    \"\"\"\n",
    "    found = set(report_sections_dict.keys())\n",
    "    missing = EXPECTED_SECTIONS - found\n",
    "    if missing:\n",
    "        return f\"Missing report sections: {', '.join(sorted(missing))}.\"\n",
    "    else:\n",
    "        return \"✅ All expected sections are present.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to check alignment between section and report goals\n",
    "def check_alignment_with_goals(section_name, report_sections_dict, model=\"gpt-3.5-turbo\", temperature=0.6):\n",
    "    \"\"\"\n",
    "    Checks the alignment between the goals of the report and a specific section.\n",
    "\n",
    "    Purpose:\n",
    "    This function evaluates whether a specific section of the report aligns with the stated goals and objectives. It uses the OpenAI API to generate an evaluation of the alignment.\n",
    "\n",
    "    Parameters:\n",
    "    section_name (str): The name of the section to evaluate for alignment.\n",
    "    report_sections_dict (dict): A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.6.\n",
    "\n",
    "    Workflow:\n",
    "    1. Tries to find the \"Goals & Objectives\" section in the report.\n",
    "    2. If the \"Goals & Objectives\" section is not found, searches for goals in other sections based on keywords.\n",
    "    3. Retrieves the text of the specified section to evaluate.\n",
    "    4. If either the goals or the section text is not found, returns a warning message.\n",
    "    5. Constructs a prompt for the OpenAI API to evaluate the alignment between the goals and the specified section.\n",
    "    6. Calls the OpenAI API with tracking to get the evaluation.\n",
    "    7. Returns the evaluation or an error message if the API call fails.\n",
    "\n",
    "    Returns:\n",
    "    str: The evaluation of the alignment between the goals and the specified section, or an error message if the API call fails.\n",
    "    \"\"\"\n",
    "    # Step 1: Try exact match first\n",
    "    try:\n",
    "        response = call_openai_with_tracking(messages, model=model, temperature=temperature)\n",
    "        return response.strip()\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Failed to check alignment: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to compare two sections of a report for duplication, contradictions, or inconsistencies\n",
    "# This tool compares two sections of an IT consulting report for duplication, contradictions, or inconsistencies.\n",
    "# It also notes if one section covers content that the other should include.\n",
    "def compare_with_other_section(section_a, section_b, report_sections_dict, model=\"gpt-3.5-turbo\", temperature=0.6):\n",
    "    \"\"\"\n",
    "    Compares two sections of an IT consulting report for duplication, contradictions, or inconsistencies.\n",
    "\n",
    "    Purpose:\n",
    "    This function compares two specified sections of an IT consulting report to identify any duplication, contradictions, or inconsistencies between them. It also notes if one section covers content that the other should include.\n",
    "\n",
    "    Parameters:\n",
    "    section_a (str): The name of the first section to compare.\n",
    "    section_b (str): The name of the second section to compare.\n",
    "    report_sections_dict (dict): A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.6.\n",
    "\n",
    "    Workflow:\n",
    "    1. Retrieves the text of the specified sections from the report_sections_dict.\n",
    "    2. If either section is not found, returns a warning message.\n",
    "    3. Constructs a prompt for the OpenAI API to compare the two sections.\n",
    "    4. Calls the OpenAI API with tracking to get the comparison.\n",
    "    5. Returns the comparison or an error message if the API call fails.\n",
    "\n",
    "    Returns:\n",
    "    str: A summary of the comparison between the two sections, or an error message if the API call fails.\n",
    "    \"\"\"\n",
    "    text_a = report_sections_dict.get(section_a)\n",
    "    text_b = report_sections_dict.get(section_b)\n",
    "\n",
    "    if not text_a or not text_b:\n",
    "        return f\"⚠️ One or both sections not found: '{section_a}' or '{section_b}'\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are comparing two sections of an IT consulting report.\\n\"\n",
    "        f\"Identify any duplication, contradictions, or inconsistencies between them.\\n\"\n",
    "        f\"Also note if one section covers content the other should include.\\n\\n\"\n",
    "        f\"Section A: {section_a}\\n{text_a}\\n\\n\"\n",
    "        f\"Section B: {section_b}\\n{text_b}\\n\\n\"\n",
    "        \"Provide a 3-5 sentence summary of your comparison:\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    try:\n",
    "        response = call_openai_with_tracking(messages, model=model, temperature=temperature)\n",
    "        return response.strip()\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Failed to compare sections: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show agent memory\n",
    "def show_agent_memory(agent):\n",
    "    \"\"\"\n",
    "    Displays a snapshot of the agent's memory, including section notes, cross-section observations, and tool usage history.\n",
    "\n",
    "    Purpose:\n",
    "    This function provides a detailed view of the agent's internal memory, which includes notes for each section, observations comparing different sections, and the history of tool usage. This is useful for understanding the agent's reasoning process and the actions it has taken.\n",
    "\n",
    "    Parameters:\n",
    "    agent (ReActConsultantAgent): An instance of the ReActConsultantAgent class, which contains the memory data to be displayed.\n",
    "\n",
    "    Workflow:\n",
    "    1. Prints a header \"Agent Memory Snapshot\".\n",
    "    2. Prints the section notes stored in the agent's memory.\n",
    "    3. Prints the cross-section observations stored in the agent's memory.\n",
    "    4. Prints the tool usage history stored in the agent's memory.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"\\n🧠 Agent Memory Snapshot\\n\")\n",
    "\n",
    "    print(\"🔹 Section Notes:\")\n",
    "    for section, notes in agent.memory[\"section_notes\"].items():\n",
    "        print(f\"- {section}:\")\n",
    "        for note in notes:\n",
    "            print(f\"  • {note}\")\n",
    "\n",
    "    print(\"\\n🔹 Cross-Section Observations:\")\n",
    "    for a, b, obs in agent.memory[\"cross_section_flags\"]:\n",
    "        print(f\"- {a} vs. {b}: {obs}\")\n",
    "\n",
    "    print(\"\\n🔹 Tool History:\")\n",
    "    for step, action, section in agent.memory[\"tool_history\"]:\n",
    "        print(f\"Step {step} | {action} | Section: {section}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_summary(agent, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
    "    \"\"\"\n",
    "    Generates a final summary for the client based on the agent's memory of section insights and cross-section observations.\n",
    "\n",
    "    Purpose:\n",
    "    This function constructs a prompt using the agent's memory of section insights and cross-section observations to generate a final summary for the client. It uses the OpenAI API to create a concise summary covering strengths, issues, and overall alignment with goals.\n",
    "\n",
    "    Parameters:\n",
    "    agent (ReActConsultantAgent): An instance of the ReActConsultantAgent class, which contains the memory data to be used for generating the summary.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "\n",
    "    Workflow:\n",
    "    1. Retrieves section notes and cross-section observations from the agent's memory.\n",
    "    2. Constructs a prompt that includes the section insights and cross-section observations.\n",
    "    3. Adds instructions to write a short, clear 4-6 sentence final summary covering strengths, issues, and overall alignment with goals.\n",
    "    4. Creates a list of messages with the constructed prompt.\n",
    "    5. Calls the OpenAI API with tracking using the call_openai_with_tracking function.\n",
    "    6. If the API call is successful, returns the generated summary.\n",
    "    7. If an exception occurs, returns a failure message with the exception details.\n",
    "\n",
    "    Returns:\n",
    "    str: The generated final summary or a failure message if the API call fails.\n",
    "    \"\"\"\n",
    "    # Build a summary prompt using memory\n",
    "    notes_by_section = agent.memory.get(\"section_notes\", {})\n",
    "    cross_section = agent.memory.get(\"cross_section_flags\", [])\n",
    "\n",
    "    prompt = \"You are a senior consultant wrapping up your review of an IT strategy report.\\n\"\n",
    "    prompt += \"Use the following section insights and cross-section observations to write a final summary for the client.\\n\\n\"\n",
    "\n",
    "    for section, notes in notes_by_section.items():\n",
    "        prompt += f\"Section: {section}\\n\"\n",
    "        for note in notes:\n",
    "            prompt += f\"- {note}\\n\"\n",
    "        prompt += \"\\n\"\n",
    "\n",
    "    if cross_section:\n",
    "        prompt += \"Cross-Section Findings:\\n\"\n",
    "        for a, b, obs in cross_section:\n",
    "            prompt += f\"- {a} vs. {b}: {obs}\\n\"\n",
    "        prompt += \"\\n\"\n",
    "\n",
    "    prompt += \"Write a short, clear 4-6 sentence final summary covering strengths, issues, and overall alignment with goals.\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    try:\n",
    "        return call_openai_with_tracking(messages, model=model, temperature=temperature).strip()\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Failed to generate final summary: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_report_to_markdown(agent, filename=\"consultant_ai_report.md\"):\n",
    "    \"\"\"\n",
    "    Exports the consulting report review to a markdown file.\n",
    "\n",
    "    Purpose:\n",
    "    This function generates a markdown file summarizing the consulting report review, including the final summary, section insights, and cross-section findings.\n",
    "\n",
    "    Parameters:\n",
    "    agent (ReActConsultantAgent): An instance of the ReActConsultantAgent class, which contains the memory data to be exported.\n",
    "    filename (str): The name of the markdown file to save. Default is \"consultant_ai_report.md\".\n",
    "\n",
    "    Workflow:\n",
    "    1. Creates an output directory if it does not exist.\n",
    "    2. Opens the specified file in write mode.\n",
    "    3. Writes the report title to the file.\n",
    "    4. Retrieves the final summary from the agent's memory and writes it to the file.\n",
    "    5. Iterates through the section notes in the agent's memory and writes each section's insights to the file.\n",
    "    6. If there are cross-section findings, writes them to the file.\n",
    "    7. Prints a confirmation message indicating the file has been saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    output_dir = \"./outputs\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    filename = os.path.join(output_dir, filename)\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"# 🧾 AI-Powered Consulting Report\\n\\n\")\n",
    "\n",
    "        # Final summary\n",
    "        final = agent.memory.get(\"final_summary\", \"No final summary generated.\")\n",
    "        f.write(\"## Final Summary\\n\\n\")\n",
    "        f.write(final + \"\\n\\n\")\n",
    "\n",
    "        # Section Notes\n",
    "        f.write(\"## Section Insights\\n\")\n",
    "        for section, notes in agent.memory[\"section_notes\"].items():\n",
    "            f.write(f\"\\n### {section}\\n\")\n",
    "            for note in notes:\n",
    "                f.write(f\"- {note}\\n\")\n",
    "\n",
    "        # Cross-section\n",
    "        if agent.memory[\"cross_section_flags\"]:\n",
    "            f.write(\"\\n## Cross-Section Findings\\n\")\n",
    "            for a, b, obs in agent.memory[\"cross_section_flags\"]:\n",
    "                f.write(f\"- **{a} vs. {b}**: {obs}\\n\")\n",
    "\n",
    "    print(f\"✅ Markdown report saved as: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_report_to_markdown_and_pdf(agent, markdown_file=\"consultant_ai_report.md\", pdf_file=\"consultant_ai_report.pdf\"):\n",
    "    \"\"\"\n",
    "    Exports the consulting report review to both a markdown file and a PDF file.\n",
    "\n",
    "    Purpose:\n",
    "    This function generates a markdown file summarizing the consulting report review and then converts it to a PDF file. It ensures that the output directory exists, exports the report to markdown, converts the markdown to HTML, and finally renders the HTML to a PDF file.\n",
    "\n",
    "    Parameters:\n",
    "    agent (ReActConsultantAgent): An instance of the ReActConsultantAgent class, which contains the memory data to be exported.\n",
    "    markdown_file (str): The name of the markdown file to save. Default is \"consultant_ai_report.md\".\n",
    "    pdf_file (str): The name of the PDF file to save. Default is \"consultant_ai_report.pdf\".\n",
    "\n",
    "    Workflow:\n",
    "    1. Ensures the output directory exists.\n",
    "    2. Exports the report to a markdown file using the export_report_to_markdown function.\n",
    "    3. Reads the markdown file and converts its content to HTML.\n",
    "    4. Optionally wraps the HTML content in a basic HTML page structure.\n",
    "    5. Saves the HTML content to a temporary file.\n",
    "    6. Uses Playwright to render the HTML file to a PDF file.\n",
    "    7. Handles any exceptions that occur during the PDF rendering process and prints an appropriate message.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    output_dir = \"../outputs/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    markdown_file = os.path.join(output_dir, markdown_file)\n",
    "    pdf_file = os.path.join(output_dir, pdf_file)\n",
    "    \n",
    "    # Step 1: Export to Markdown\n",
    "    export_report_to_markdown(agent, filename=markdown_file)\n",
    "\n",
    "    # Step 2: Convert to HTML\n",
    "    with open(markdown_file, \"r\") as f:\n",
    "        md_text = f.read()\n",
    "    html_content = markdown(md_text)\n",
    "\n",
    "    # Optional: wrap in basic HTML page\n",
    "    full_html = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\">\n",
    "        <title>Consulting Report</title>\n",
    "        <style>\n",
    "            body {{ font-family: sans-serif; margin: 40px; line-height: 1.6; }}\n",
    "            h1, h2, h3 {{ color: #003366; }}\n",
    "            ul {{ margin-top: 0; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    {html_content}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 3: Save HTML and render to PDF\n",
    "    temp_html_path = os.path.join(output_dir, \"temp_report.html\")\n",
    "    with open(\"temp_report.html\", \"w\") as f:\n",
    "        f.write(full_html)\n",
    "\n",
    "    try:\n",
    "        with sync_playwright() as p:\n",
    "            browser = p.chromium.launch()\n",
    "            page = browser.new_page()\n",
    "            page.goto(\"file://\" + os.path.abspath(\"temp_report.html\"))\n",
    "            page.pdf(path=pdf_file, format=\"A4\")\n",
    "            browser.close()\n",
    "            print(f\"✅ PDF report saved as: {pdf_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ PDF export failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 3: Load Data** <a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample IT consulting report (replace with real one later)\n",
    "# You can later replace this with a real one or load from a file.\n",
    "# We can add file upload later (open(\"report.txt\").read())\n",
    "sample_report = \"\"\"\n",
    "Client: HealthConnect Systems\n",
    "Industry: Healthcare\n",
    "Project: IT Modernization Assessment\n",
    "\n",
    "Summary:\n",
    "HealthConnect currently operates on-premise infrastructure for its core clinical systems. While some departments use SaaS tools, there is no centralized cloud strategy. Security policies are documented but not consistently followed. There is no formal data governance framework. Leadership has expressed interest in migrating systems to the cloud.\n",
    "\n",
    "Key Recommendations:\n",
    "1. Conduct a cloud readiness assessment.\n",
    "2. Begin phased migration of CRM and EHR systems.\n",
    "3. Establish a data governance committee.\n",
    "4. Update security protocols to align with NIST standards.\n",
    "\n",
    "Timeline: Estimated at 6–12 months for full migration planning and execution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 4: Pre-process Data** <a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Header:\n",
      "Client: HealthConnect Systems\n",
      "Industry: Healthcare\n",
      "Project: IT Modernization Assessment\n",
      "------------------------------------------------------------\n",
      "📌 Summary:\n",
      "HealthConnect currently operates on-premise infrastructure for its core clinical systems. While some departments use SaaS tools, there is no centralized cloud strategy. Security policies are documented but not consistently followed. There is no formal data governance framework. Leadership has expressed interest in migrating systems to the cloud.\n",
      "------------------------------------------------------------\n",
      "📌 Key Recommendations:\n",
      "1. Conduct a cloud readiness assessment.\n",
      "2. Begin phased migration of CRM and EHR systems.\n",
      "3. Establish a data governance committee.\n",
      "4. Update security protocols to align with NIST standards.\n",
      "Timeline: Estimated at 6–12 months for full migration planning and execution.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run it on the sample report\n",
    "report_sections = split_report_into_sections(sample_report)\n",
    "\n",
    "# Display for verification\n",
    "for section, content in report_sections.items():\n",
    "    print(f\"📌 {section}:\\n{content}\\n{'-'*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 5: Model - Basic: Single-Hop Reasoning + Static Action Loop** <a id=\"5\"></a>\n",
    "\n",
    "1. Iterate through sections of report\n",
    "2. Send each section to ChatGPT for feedback\n",
    "3. Summarize feedback \n",
    "\n",
    "## **5.1 Initialize Agent** <a id=\"5.1\"></a> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the reasoning agent\n",
    "agent = ITReportReviewer(report_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2 Run Agent** <a id=\"5.2\"></a> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell execution skipped.\n"
     ]
    }
   ],
   "source": [
    "# Boolean to control cell execution\n",
    "execute_cell = False\n",
    "\n",
    "if execute_cell:\n",
    "    # Define the order in which we want to review sections\n",
    "    sections_to_review = list(report_sections.keys())\n",
    "\n",
    "    # Loop through each section and generate a review\n",
    "    for section in sections_to_review:\n",
    "        agent.review_section(section)\n",
    "else:\n",
    "    print(\"Cell execution skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Prompt: 54 tokens | Completion: 434 tokens | Total so far: 488 tokens\n",
      "💰 Estimated cost so far: $0.0007 USD\n",
      "📋 Final Summary of the Report Review:\n",
      "\n",
      "Overall, the internal report assessment shows a comprehensive analysis of the IT strategy. Here is a summary based on the section reviews:\n",
      "\n",
      "1. **Executive Summary**:\n",
      "   - Strengths: The executive summary provides a clear and concise overview of the IT strategy assessment.\n",
      "   - Gaps: It could benefit from including key findings and recommendations to provide a more holistic view right at the beginning.\n",
      "\n",
      "2. **Current IT Landscape**:\n",
      "   - Strengths: The section offers a detailed description of the existing IT infrastructure and systems.\n",
      "   - Gaps: It lacks an evaluation of the current IT capabilities and how they align with business goals and industry standards.\n",
      "\n",
      "3. **SWOT Analysis**:\n",
      "   - Strengths: The SWOT analysis identifies internal strengths and weaknesses along with external opportunities and threats effectively.\n",
      "   - Gaps: It would be more valuable to provide specific examples or data to support each point in the analysis.\n",
      "\n",
      "4. **IT Strategy Alignment**:\n",
      "   - Strengths: The report discusses the alignment of IT strategy with business objectives.\n",
      "   - Gaps: It needs to elaborate more on the specific ways in which IT strategy supports or hinders the achievement of business goals.\n",
      "\n",
      "5. **Recommendations**:\n",
      "   - Strengths: The recommendations are provided based on the analysis conducted.\n",
      "   - Gaps: The recommendations could be more actionable and measurable to facilitate implementation.\n",
      "\n",
      "Overall, the report demonstrates a good understanding of the current IT landscape and strategic alignment but lacks depth in certain areas such as actionable recommendations and specific examples to support the analysis.\n",
      "\n",
      "To improve the report, consider the following next steps:\n",
      "- Enhance the executive summary by including key findings and actionable recommendations.\n",
      "- Provide more detailed analysis of the current IT capabilities and how they impact business outcomes.\n",
      "- Strengthen the SWOT analysis by including specific examples or data points.\n",
      "- Elaborate on how the IT strategy directly contributes to achieving business objectives.\n",
      "- Ensure recommendations are specific, measurable, achievable, relevant, and timely (SMART) to facilitate implementation.\n",
      "\n",
      "By addressing these areas, the report can become more robust and actionable, guiding the organization towards an effective IT strategy that aligns with its business objectives.\n"
     ]
    }
   ],
   "source": [
    "# Call the summarize_full_review function to get the final summary\n",
    "final_summary = summarize_full_review(agent)\n",
    "print(\"📋 Final Summary of the Report Review:\\n\")\n",
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 6: Model - ReAct** <a id=\"6\"></a>\n",
    "\n",
    "1. **Think** about each section (with ChatGPT)\n",
    "2. Decide on and take an **action**\n",
    "3. **Observe** the results and loop back to step 1 with new reasoning\n",
    "\n",
    "## **6.1 Simple Agent - Predefined Actions** <a id=\"6.1\"></a> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell execution skipped.\n"
     ]
    }
   ],
   "source": [
    "# Boolean to control cell execution\n",
    "execute_cell = False\n",
    "\n",
    "if execute_cell:\n",
    "    # Choose a section to run ReAct on\n",
    "    section_name = \"Summary\"\n",
    "    section_text = report_sections.get(section_name, \"\")\n",
    "\n",
    "    # Initialize the ReAct agent\n",
    "    react_agent = ReActConsultantAgent(section_name, section_text)\n",
    "\n",
    "    # Run the ReAct loop\n",
    "    react_review_history = run_react_loop_static(react_agent)\n",
    "else:\n",
    "    print(\"Cell execution skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.2 Agent 2 - Custom & Pre-Built Tools** <a id=\"6.2\"></a> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell execution skipped.\n"
     ]
    }
   ],
   "source": [
    "## ReAct Loop with Tool Usage Tracking - one section at a time\n",
    "\n",
    "# Boolean to control cell execution\n",
    "execute_cell = False\n",
    "\n",
    "if execute_cell:\n",
    "    # Choose a section to run ReAct on\n",
    "    section_name = \"Key Recommendations\"\n",
    "    section_text = report_sections.get(section_name, \"\")\n",
    "\n",
    "    # Initialize the ReAct agent\n",
    "    react_agent = ReActConsultantAgent(section_name, section_text)\n",
    "\n",
    "    # Run the ReAct loop\n",
    "    react_review_history = run_react_loop_check_withTool(react_agent)\n",
    "\n",
    "    # Print tool usage summary\n",
    "    tool_usage = print_tool_usage(react_agent)\n",
    "    plot_tool_usage(react_agent.tool_usage)\n",
    "    \n",
    "else:\n",
    "    print(\"Cell execution skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Step 1\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Header\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\nClient: HealthConnect Systems\\nIndustry: Healthcare\\nProject: IT Modernization Assessment\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 856 tokens | Completion: 26 tokens | Total so far: 1370 tokens\n",
      "💰 Estimated cost so far: $0.0021 USD\n",
      "\n",
      "🔁 Step 1\n",
      "🧠 Thought: The section title \"Header\" is too generic and does not provide specific information about the content.\n",
      "⚙️ Action: recommend_fix\n",
      "👀 Observation: The recommendation improves the section's clarity and compliance.\n",
      "\n",
      "🔁 Step 2\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Header\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\nClient: HealthConnect Systems\\nIndustry: Healthcare\\nProject: IT Modernization Assessment\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 895 tokens | Completion: 28 tokens | Total so far: 2293 tokens\n",
      "💰 Estimated cost so far: $0.0034 USD\n",
      "\n",
      "🔁 Step 2\n",
      "🧠 Thought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\n",
      "⚙️ Action: recommend_fix\n",
      "👀 Observation: The recommendation improves the section's clarity and compliance.\n",
      "\n",
      "🔁 Step 3\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Header\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\nClient: HealthConnect Systems\\nIndustry: Healthcare\\nProject: IT Modernization Assessment\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 936 tokens | Completion: 32 tokens | Total so far: 3261 tokens\n",
      "💰 Estimated cost so far: $0.0049 USD\n",
      "\n",
      "🔁 Step 3\n",
      "🧠 Thought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\n",
      "⚙️ Action: recommend_fix\n",
      "👀 Observation: The recommendation improves the section's clarity and compliance.\n",
      "\n",
      "🔁 Step 4\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Header\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\nClient: HealthConnect Systems\\nIndustry: Healthcare\\nProject: IT Modernization Assessment\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 981 tokens | Completion: 26 tokens | Total so far: 4268 tokens\n",
      "💰 Estimated cost so far: $0.0064 USD\n",
      "\n",
      "🔁 Step 4\n",
      "🧠 Thought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\n",
      "⚙️ Action: recommend_fix\n",
      "👀 Observation: The recommendation improves the section's clarity and compliance.\n",
      "\n",
      "🔁 Step 5\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Header\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\nClient: HealthConnect Systems\\nIndustry: Healthcare\\nProject: IT Modernization Assessment\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1020 tokens | Completion: 25 tokens | Total so far: 5313 tokens\n",
      "💰 Estimated cost so far: $0.0080 USD\n",
      "\n",
      "🔁 Step 5\n",
      "🧠 Thought: I should provide specific examples of alternative titles that could better represent the content of the section.\n",
      "⚙️ Action: recommend_fix\n",
      "👀 Observation: The recommendation improves the section's clarity and compliance.\n",
      "\n",
      "🔁 Step 1\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Summary\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\nHealthConnect currently operates on-premise infrastructure for its core clinical systems. While some departments use SaaS tools, there is no centralized cloud strategy. Security policies are documented but not consistently followed. There is no formal data governance framework. Leadership has expressed interest in migrating systems to the cloud.\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should provide specific examples of alternative titles that could better represent the content of the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1098 tokens | Completion: 36 tokens | Total so far: 6447 tokens\n",
      "💰 Estimated cost so far: $0.0097 USD\n",
      "\n",
      "🔁 Step 1\n",
      "🧠 Thought: I should recommend a revised section title that highlights the current state of IT infrastructure, security policies, data governance, and the interest in cloud migration.\n",
      "⚙️ Action: recommend_fix\n",
      "👀 Observation: The recommendation improves the section's clarity and compliance.\n",
      "\n",
      "🔁 Step 2\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Summary\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\nHealthConnect currently operates on-premise infrastructure for its core clinical systems. While some departments use SaaS tools, there is no centralized cloud strategy. Security policies are documented but not consistently followed. There is no formal data governance framework. Leadership has expressed interest in migrating systems to the cloud.\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should provide specific examples of alternative titles that could better represent the content of the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should recommend a revised section title that highlights the current state of IT infrastructure, security policies, data governance, and the interest in cloud migration.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1147 tokens | Completion: 65 tokens | Total so far: 7659 tokens\n",
      "💰 Estimated cost so far: $0.0115 USD\n",
      "\n",
      "🔁 Step 2\n",
      "🧠 Thought: I should consider suggesting a more detailed and informative title such as \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\".\n",
      "⚙️ Action: recommend_fix\n",
      "👀 Observation: The recommendation improves the section's clarity and compliance.\n",
      "\n",
      "🔁 Step 3\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Summary\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\nHealthConnect currently operates on-premise infrastructure for its core clinical systems. While some departments use SaaS tools, there is no centralized cloud strategy. Security policies are documented but not consistently followed. There is no formal data governance framework. Leadership has expressed interest in migrating systems to the cloud.\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should provide specific examples of alternative titles that could better represent the content of the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should recommend a revised section title that highlights the current state of IT infrastructure, security policies, data governance, and the interest in cloud migration.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should consider suggesting a more detailed and informative title such as \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\".\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1198 tokens | Completion: 63 tokens | Total so far: 8920 tokens\n",
      "💰 Estimated cost so far: $0.0134 USD\n",
      "\n",
      "🔁 Step 3\n",
      "🧠 Thought: I should review the content of the section to ensure it aligns with the suggested revised title.\n",
      "⚙️ Action: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\n",
      "👀 Observation: ⚠️ Failed to check alignment: name 'messages' is not defined\n",
      "\n",
      "🔁 Step 4\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Summary\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\nHealthConnect currently operates on-premise infrastructure for its core clinical systems. While some departments use SaaS tools, there is no centralized cloud strategy. Security policies are documented but not consistently followed. There is no formal data governance framework. Leadership has expressed interest in migrating systems to the cloud.\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should provide specific examples of alternative titles that could better represent the content of the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should recommend a revised section title that highlights the current state of IT infrastructure, security policies, data governance, and the interest in cloud migration.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should consider suggesting a more detailed and informative title such as \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\".\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should review the content of the section to ensure it aligns with the suggested revised title.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1264 tokens | Completion: 51 tokens | Total so far: 10235 tokens\n",
      "💰 Estimated cost so far: $0.0154 USD\n",
      "\n",
      "🔁 Step 4\n",
      "🧠 Thought: I should address the error message and try to check the alignment of the section content with the suggested revised title again.\n",
      "⚙️ Action: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\n",
      "👀 Observation: ⚠️ Failed to check alignment: name 'messages' is not defined\n",
      "\n",
      "🔁 Step 5\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Summary\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\nHealthConnect currently operates on-premise infrastructure for its core clinical systems. While some departments use SaaS tools, there is no centralized cloud strategy. Security policies are documented but not consistently followed. There is no formal data governance framework. Leadership has expressed interest in migrating systems to the cloud.\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should provide specific examples of alternative titles that could better represent the content of the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should recommend a revised section title that highlights the current state of IT infrastructure, security policies, data governance, and the interest in cloud migration.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should consider suggesting a more detailed and informative title such as \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\".\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should review the content of the section to ensure it aligns with the suggested revised title.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should address the error message and try to check the alignment of the section content with the suggested revised title again.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1334 tokens | Completion: 63 tokens | Total so far: 11632 tokens\n",
      "💰 Estimated cost so far: $0.0174 USD\n",
      "\n",
      "🔁 Step 5\n",
      "🧠 Thought: I should try to manually assess the alignment of the section content with the suggested revised title since the tool failed to provide the comparison.\n",
      "⚙️ Action: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\n",
      "👀 Observation: Unrecognized action.\n",
      "\n",
      "🔁 Step 1\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Key Recommendations\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\n1. Conduct a cloud readiness assessment.\\n2. Begin phased migration of CRM and EHR systems.\\n3. Establish a data governance committee.\\n4. Update security protocols to align with NIST standards.\\nTimeline: Estimated at 6–12 months for full migration planning and execution.\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should provide specific examples of alternative titles that could better represent the content of the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should recommend a revised section title that highlights the current state of IT infrastructure, security policies, data governance, and the interest in cloud migration.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should consider suggesting a more detailed and informative title such as \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\".\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should review the content of the section to ensure it aligns with the suggested revised title.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should address the error message and try to check the alignment of the section content with the suggested revised title again.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should try to manually assess the alignment of the section content with the suggested revised title since the tool failed to provide the comparison.\\nAction: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1403 tokens | Completion: 73 tokens | Total so far: 13108 tokens\n",
      "💰 Estimated cost so far: $0.0197 USD\n",
      "\n",
      "🔁 Step 1\n",
      "🧠 Thought: Since the tool failed to check the alignment of the section content with the suggested revised title, I should manually review the content to ensure it reflects the aspects mentioned in the proposed title.\n",
      "⚙️ Action: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\n",
      "👀 Observation: Unrecognized action.\n",
      "\n",
      "🔁 Step 2\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Key Recommendations\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\n1. Conduct a cloud readiness assessment.\\n2. Begin phased migration of CRM and EHR systems.\\n3. Establish a data governance committee.\\n4. Update security protocols to align with NIST standards.\\nTimeline: Estimated at 6–12 months for full migration planning and execution.\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should provide specific examples of alternative titles that could better represent the content of the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should recommend a revised section title that highlights the current state of IT infrastructure, security policies, data governance, and the interest in cloud migration.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should consider suggesting a more detailed and informative title such as \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\".\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should review the content of the section to ensure it aligns with the suggested revised title.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should address the error message and try to check the alignment of the section content with the suggested revised title again.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should try to manually assess the alignment of the section content with the suggested revised title since the tool failed to provide the comparison.\\nAction: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nThought: Since the tool failed to check the alignment of the section content with the suggested revised title, I should manually review the content to ensure it reflects the aspects mentioned in the proposed title.\\nAction: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1482 tokens | Completion: 67 tokens | Total so far: 14657 tokens\n",
      "💰 Estimated cost so far: $0.0220 USD\n",
      "\n",
      "🔁 Step 2\n",
      "🧠 Thought: I should manually review the content of the section to ensure it covers aspects related to IT infrastructure, security policies, data governance, and cloud migration interest.\n",
      "⚙️ Action: review content of the section to check alignment with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\n",
      "👀 Observation: Unrecognized action.\n",
      "\n",
      "🔁 Step 3\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Key Recommendations\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\n1. Conduct a cloud readiness assessment.\\n2. Begin phased migration of CRM and EHR systems.\\n3. Establish a data governance committee.\\n4. Update security protocols to align with NIST standards.\\nTimeline: Estimated at 6–12 months for full migration planning and execution.\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should provide specific examples of alternative titles that could better represent the content of the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should recommend a revised section title that highlights the current state of IT infrastructure, security policies, data governance, and the interest in cloud migration.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should consider suggesting a more detailed and informative title such as \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\".\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should review the content of the section to ensure it aligns with the suggested revised title.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should address the error message and try to check the alignment of the section content with the suggested revised title again.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should try to manually assess the alignment of the section content with the suggested revised title since the tool failed to provide the comparison.\\nAction: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nThought: Since the tool failed to check the alignment of the section content with the suggested revised title, I should manually review the content to ensure it reflects the aspects mentioned in the proposed title.\\nAction: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nThought: I should manually review the content of the section to ensure it covers aspects related to IT infrastructure, security policies, data governance, and cloud migration interest.\\nAction: review content of the section to check alignment with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1555 tokens | Completion: 68 tokens | Total so far: 16280 tokens\n",
      "💰 Estimated cost so far: $0.0244 USD\n",
      "\n",
      "🔁 Step 3\n",
      "🧠 Thought: I should manually review the content of the section to ensure it covers aspects related to IT infrastructure, security policies, data governance, and cloud migration interest.\n",
      "⚙️ Action: review the content of the section to check alignment with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\n",
      "👀 Observation: Unrecognized action.\n",
      "\n",
      "🔁 Step 4\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Key Recommendations\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\n1. Conduct a cloud readiness assessment.\\n2. Begin phased migration of CRM and EHR systems.\\n3. Establish a data governance committee.\\n4. Update security protocols to align with NIST standards.\\nTimeline: Estimated at 6–12 months for full migration planning and execution.\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should provide specific examples of alternative titles that could better represent the content of the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should recommend a revised section title that highlights the current state of IT infrastructure, security policies, data governance, and the interest in cloud migration.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should consider suggesting a more detailed and informative title such as \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\".\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should review the content of the section to ensure it aligns with the suggested revised title.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should address the error message and try to check the alignment of the section content with the suggested revised title again.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should try to manually assess the alignment of the section content with the suggested revised title since the tool failed to provide the comparison.\\nAction: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nThought: Since the tool failed to check the alignment of the section content with the suggested revised title, I should manually review the content to ensure it reflects the aspects mentioned in the proposed title.\\nAction: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nThought: I should manually review the content of the section to ensure it covers aspects related to IT infrastructure, security policies, data governance, and cloud migration interest.\\nAction: review content of the section to check alignment with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nThought: I should manually review the content of the section to ensure it covers aspects related to IT infrastructure, security policies, data governance, and cloud migration interest.\\nAction: review the content of the section to check alignment with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1629 tokens | Completion: 68 tokens | Total so far: 17977 tokens\n",
      "💰 Estimated cost so far: $0.0270 USD\n",
      "\n",
      "🔁 Step 4\n",
      "🧠 Thought: I should manually review the content of the section to ensure it covers aspects related to IT infrastructure, security policies, data governance, and cloud migration interest.\n",
      "⚙️ Action: review the content of the section to check alignment with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\n",
      "👀 Observation: Unrecognized action.\n",
      "\n",
      "🔁 Step 5\n",
      "🧠 Prompt: [{'role': 'user', 'content': 'You are an expert IT strategy consultant reviewing a report section titled \\'Key Recommendations\\'.\\nYou are using ReAct (Reason + Act) to think through the review.\\n\\nFormat each response like this:\\nThought: <your reasoning>\\nAction: <one of: check_guideline, keyword_match_in_section, check_timeline_feasibility, search_report, ask_question, flag_risk, recommend_fix, summarize, tool_help, suggest_tool_for, search_web, check_for_jargon, generate_client_questions, highlight_missing_sections, check_alignment_with_goals, compare_with_other_section, final_summary\\'\\n\\nAvailable tools:\\n\\n- check_guideline (vv1.0): Look up a best practice for a given topic\\n  Usage: check_guideline[\"cloud security\"]\\n  Example: check_guideline[\"data governance\"]\\n  Example: check_guideline[\"migration strategy\"]\\n\\n- keyword_match_in_section (vv1.0): Check if a keyword appears in the current section\\n  Usage: keyword_match_in_section[\"encryption\"]\\n  Example: keyword_match_in_section[\"stakeholders\"]\\n\\n- check_timeline_feasibility (vv1.0): Check if a project timeline is realistic for migration\\n  Usage: check_timeline_feasibility[\"12 weeks\"]\\n  Example: check_timeline_feasibility[\"3 months\"]\\n\\n- search_report (vv1.0): Search the entire report for a concept or term\\n  Usage: search_report[\"data governance\"]\\n  Example: search_report[\"Zero Trust\"]\\n\\n- ask_question (vv1.0): Ask a clarifying question about the report\\n  Usage: ask_question\\n  Example: ask_question\\n\\n- flag_risk (vv1.0): Flag a gap, issue, or concern in the section\\n  Usage: flag_risk\\n  Example: flag_risk\\n\\n- recommend_fix (vv1.0): Suggest a specific improvement\\n  Usage: recommend_fix\\n  Example: recommend_fix\\n\\n- summarize (vv1.0): Summarize your review and end the loop\\n  Usage: summarize\\n  Example: summarize\\n\\n- tool_help (vv1.0): View descriptions, usage, and examples for available tools\\n  Usage: tool_help\\n  Example: tool_help\\n\\n- suggest_tool_for (vv1.0): Ask which tool best supports a particular goal or intent\\n  Usage: suggest_tool_for[\"goal or intent\"]\\n  Example: suggest_tool_for[\"check if encryption is included\"]\\n  Example: suggest_tool_for[\"evaluate feasibility of 12-week timeline\"]\\n\\n- search_web (vv1.0): Look up a concept, framework, or term on the web (DuckDuckGo)\\n  Usage: search_web[\"Zero Trust model\"]\\n  Example: search_web[\"data mesh\"]\\n\\n- check_for_jargon (vv1.0): Identify jargon or overly technical terms that may need simplification\\n  Usage: check_for_jargon\\n  Example: check_for_jargon\\n\\n- generate_client_questions (vv1.0): Generate clarifying or skeptical questions a client might ask about the section\\n  Usage: generate_client_questions\\n  Example: generate_client_questions\\n\\n- highlight_missing_sections (vv1.0): Identify which expected sections are missing from the report\\n  Usage: highlight_missing_sections\\n  Example: highlight_missing_sections\\n\\n- check_alignment_with_goals (vv1.0): Evaluate how well a report section aligns with the stated goals\\n  Usage: check_alignment_with_goals[\"section_name\"]\\n  Example: check_alignment_with_goals[\"Key Recommendations\"]\\n\\n- compare_with_other_section (vv1.0): Compare two sections to identify overlaps, contradictions, or gaps\\n  Usage: compare_with_other_section[\"sectionA\", \"sectionB\"]\\n  Example: compare_with_other_section[\"Key Recommendations\", \"Roadmap & Timeline\"]\\n  Example: compare_with_other_section[\"Future State Vision\", \"Technology Architecture\"]\\n\\n- final_summary (vv1.0): Generate a final client-facing summary based on insights gathered across all sections\\n  Usage: final_summary\\n  Example: final_summary\\nHere is the section content:\\n1. Conduct a cloud readiness assessment.\\n2. Begin phased migration of CRM and EHR systems.\\n3. Establish a data governance committee.\\n4. Update security protocols to align with NIST standards.\\nTimeline: Estimated at 6–12 months for full migration planning and execution.\\n\\nThought: The section title \"Header\" is too generic and does not provide specific information about the content.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: The section title should be more descriptive to give readers a clear idea of what to expect in the report.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: It would be beneficial to suggest a more informative and relevant title for the section that aligns with the project goals and scope.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should suggest potential alternative titles that are more descriptive and specific to the content within the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should provide specific examples of alternative titles that could better represent the content of the section.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should recommend a revised section title that highlights the current state of IT infrastructure, security policies, data governance, and the interest in cloud migration.\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should consider suggesting a more detailed and informative title such as \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\".\\nAction: recommend_fix\\nObservation: The recommendation improves the section\\'s clarity and compliance.\\n\\nThought: I should review the content of the section to ensure it aligns with the suggested revised title.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should address the error message and try to check the alignment of the section content with the suggested revised title again.\\nAction: check_alignment_with_goals[\"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"]\\nObservation: ⚠️ Failed to check alignment: name \\'messages\\' is not defined\\n\\nThought: I should try to manually assess the alignment of the section content with the suggested revised title since the tool failed to provide the comparison.\\nAction: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nThought: Since the tool failed to check the alignment of the section content with the suggested revised title, I should manually review the content to ensure it reflects the aspects mentioned in the proposed title.\\nAction: manually assess the alignment of the section content with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nThought: I should manually review the content of the section to ensure it covers aspects related to IT infrastructure, security policies, data governance, and cloud migration interest.\\nAction: review content of the section to check alignment with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nThought: I should manually review the content of the section to ensure it covers aspects related to IT infrastructure, security policies, data governance, and cloud migration interest.\\nAction: review the content of the section to check alignment with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nThought: I should manually review the content of the section to ensure it covers aspects related to IT infrastructure, security policies, data governance, and cloud migration interest.\\nAction: review the content of the section to check alignment with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\\nObservation: Unrecognized action.\\n\\nWhat is your next Thought and Action?'}]\n",
      "🔢 Prompt: 1703 tokens | Completion: 68 tokens | Total so far: 19748 tokens\n",
      "💰 Estimated cost so far: $0.0296 USD\n",
      "\n",
      "🔁 Step 5\n",
      "🧠 Thought: I should manually review the content of the section to ensure it covers aspects related to IT infrastructure, security policies, data governance, and cloud migration interest.\n",
      "⚙️ Action: review the content of the section to check alignment with the suggested revised title \"Current State Assessment of IT Infrastructure, Security Policies, Data Governance, and Cloud Migration Interest\"\n",
      "👀 Observation: Unrecognized action.\n",
      "🔢 Prompt: 219 tokens | Completion: 119 tokens | Total so far: 20086 tokens\n",
      "💰 Estimated cost so far: $0.0301 USD\n",
      "\n",
      "🧾 Final Summary:\n",
      "\n",
      "Overall, the IT strategy report has been greatly improved through the consultant's recommendations, particularly in the headers and summary sections. The clarity and compliance of these sections have been significantly enhanced, providing a more concise and focused overview for the client. However, there are some issues that need to be addressed, such as the failed alignment check in the summary section. Moving forward, the key recommendations section should be revisited to ensure that all actions are recognized and clearly outlined. Despite these minor issues, the report is well-aligned with the client's goals and provides a strong foundation for future IT strategy implementation.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './outputs/./outputs/consultant_ai_report.md'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     agent\u001b[38;5;241m.\u001b[39mmemory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m summary\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Export the report to markdown and PDF\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mexport_report_to_markdown_and_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReport exported successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[32], line 32\u001b[0m, in \u001b[0;36mexport_report_to_markdown_and_pdf\u001b[0;34m(agent, markdown_file, pdf_file)\u001b[0m\n\u001b[1;32m     29\u001b[0m pdf_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, pdf_file)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Step 1: Export to Markdown\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mexport_report_to_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarkdown_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Step 2: Convert to HTML\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(markdown_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[31], line 27\u001b[0m, in \u001b[0;36mexport_report_to_markdown\u001b[0;34m(agent, filename)\u001b[0m\n\u001b[1;32m     25\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, filename)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     28\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# 🧾 AI-Powered Consulting Report\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Final summary\u001b[39;00m\n",
      "File \u001b[0;32m~/hockey_ai/lib/python3.13/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './outputs/./outputs/consultant_ai_report.md'"
     ]
    }
   ],
   "source": [
    "## Run ReAct on the full report of all sections\n",
    "\n",
    "# Boolean to control cell execution\n",
    "execute_cell = True\n",
    "\n",
    "if execute_cell:\n",
    "    # Create a single agent to hold memory across sections\n",
    "    agent = ReActConsultantAgent(section_name=\"Full Report\", section_text=\"\")\n",
    "\n",
    "    # Loop through each report section and run ReAct\n",
    "    for section_name, section_text in report_sections.items():\n",
    "        agent.section_name = section_name\n",
    "        agent.section_text = section_text\n",
    "        run_react_loop_check_withTool(agent)\n",
    "\n",
    "    # Generate the final summary based on the agent's memory\n",
    "    summary = generate_final_summary(agent)\n",
    "    print(\"\\n🧾 Final Summary:\\n\")\n",
    "    print(summary)\n",
    "    agent.memory[\"final_summary\"] = summary\n",
    "\n",
    "    # Export the report to markdown and PDF\n",
    "    export_report_to_markdown_and_pdf(agent)\n",
    "    print(\"Report exported successfully.\")\n",
    "else:\n",
    "    print(\"Cell execution skipped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hockey_ai",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
