{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 1: Setup and Imports** <a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not already installed (uncomment below in Jupyter)\n",
    "# !pip install openai python-dotenv\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key loaded: True\n"
     ]
    }
   ],
   "source": [
    "# Load the OpenAI API key from .env file\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check to confirm it's loaded (optional)\n",
    "print(\"‚úÖ API key loaded:\", openai.api_key is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 2: Functions** <a id=\"2\"></a>\n",
    "## **2.1 OpenAI Functions** <a id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call OpenAI's ChatCompletion API with structured messages\n",
    "def call_openai(messages, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
    "    \"\"\"\n",
    "    Calls OpenAI's ChatCompletion API with structured messages.\n",
    "\n",
    "    Parameters:\n",
    "    messages (list): A list of message dictionaries, where each dictionary contains 'role' and 'content' keys.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "\n",
    "    Workflow:\n",
    "    1. The function takes the input parameters and calls the OpenAI ChatCompletion API.\n",
    "    2. The API returns a response containing multiple choices.\n",
    "    3. The function extracts the content of the first choice from the response.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the first choice from the API response.\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to construct system + user messages for the reasoning agent\n",
    "def build_review_prompt(report_text, history=[]):\n",
    "    \"\"\"\n",
    "    Constructs system and user messages for the reasoning agent to review a consulting report.\n",
    "\n",
    "    Parameters:\n",
    "    report_text (str): The text of the consulting report to be reviewed.\n",
    "    history (list): A list of previous messages (optional). Default is an empty list.\n",
    "\n",
    "    Workflow:\n",
    "    1. The function creates a system message that sets the context for the reasoning agent.\n",
    "    2. It then creates a user message containing the consulting report text.\n",
    "    3. The function combines the system message, the history of previous messages, and the user message into a single list.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of message dictionaries, including the system message, any historical messages, and the user message.\n",
    "    \"\"\"\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an experienced IT strategy consultant. \"\n",
    "            \"You are reviewing a consulting report for completeness, clarity, risks, and alignment with best practices. \"\n",
    "            \"Think step-by-step and identify gaps, ask clarifying questions, or suggest improvements. \"\n",
    "            \"Your goal is to provide helpful, critical feedback using your expert knowledge.\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Here is the consulting report to review:\\n\\n{report_text}\"\n",
    "    }\n",
    "\n",
    "    return [system_msg] + history + [user_msg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track total tokens used and estimated cost\n",
    "total_tokens_used = 0\n",
    "estimated_cost_usd = 0.0\n",
    "\n",
    "# Cost per 1K tokens for GPT-3.5-turbo (adjust if using GPT-4)\n",
    "COST_PER_1K_TOKENS = 0.0015\n",
    "\n",
    "def call_openai_with_tracking(messages, model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=500):\n",
    "    \"\"\"\n",
    "    Calls OpenAI's ChatCompletion API with structured messages and tracks token usage and estimated cost.\n",
    "\n",
    "    Parameters:\n",
    "    messages (list): A list of message dictionaries, where each dictionary contains 'role' and 'content' keys.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "    max_tokens (int): The maximum number of tokens to generate in the completion. Default is 500.\n",
    "\n",
    "    Workflow:\n",
    "    1. The function takes the input parameters and calls the OpenAI ChatCompletion API.\n",
    "    2. The API returns a response containing multiple choices and token usage information.\n",
    "    3. The function extracts the content of the first choice from the response.\n",
    "    4. It updates the total tokens used and the estimated cost in USD.\n",
    "    5. It logs the prompt tokens, completion tokens, total tokens used so far, and the estimated cost.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the first choice from the API response.\n",
    "    \"\"\"\n",
    "    global total_tokens_used, estimated_cost_usd\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    usage = response['usage']\n",
    "    prompt_tokens = usage.get('prompt_tokens', 0)\n",
    "    completion_tokens = usage.get('completion_tokens', 0)\n",
    "    total = usage.get('total_tokens', prompt_tokens + completion_tokens)\n",
    "\n",
    "    # Update tracking\n",
    "    total_tokens_used += total\n",
    "    estimated_cost_usd += (total / 1000) * COST_PER_1K_TOKENS\n",
    "\n",
    "    # Logging\n",
    "    print(f\"üî¢ Prompt: {prompt_tokens} tokens | Completion: {completion_tokens} tokens | Total so far: {total_tokens_used} tokens\")\n",
    "    print(f\"üí∞ Estimated cost so far: ${estimated_cost_usd:.4f} USD\")\n",
    "\n",
    "    return response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 Data Preprocessing Functions** <a id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the report into sections\n",
    "def split_report_into_sections(report_text):\n",
    "    \"\"\"\n",
    "    Splits a consulting report into sections based on headers.\n",
    "\n",
    "    Parameters:\n",
    "    report_text (str): The text of the consulting report to be split into sections.\n",
    "\n",
    "    Workflow:\n",
    "    1. The function initializes an empty dictionary to store sections and sets the current section to \"Header\".\n",
    "    2. It splits the report text into lines and iterates through each line.\n",
    "    3. For each line:\n",
    "       - If the line is blank, it skips to the next line.\n",
    "       - If the line ends with a colon and contains 4 or fewer words, it is considered a section header.\n",
    "         The current section is updated to this header (without the colon), and a new entry is created in the dictionary.\n",
    "       - Otherwise, the line is added to the current section's content.\n",
    "    4. After processing all lines, the function joins the content of each section into a single string.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "    \"\"\"\n",
    "    sections = {}\n",
    "    lines = report_text.strip().split(\"\\n\")\n",
    "    current_section = \"Header\"\n",
    "    sections[current_section] = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # skip blank lines\n",
    "        elif line.endswith(\":\") and len(line.split()) <= 4: # Check if it's a section header.  If yes, create a new section with the header as the key.\n",
    "            current_section = line.replace(\":\", \"\").strip()\n",
    "            sections[current_section] = []\n",
    "        else:\n",
    "            sections[current_section].append(line) # Add the line (contents below header) to the current section\n",
    "\n",
    "    # Join section contents with newlines\n",
    "    for key in sections:\n",
    "        sections[key] = \"\\n\".join(sections[key])\n",
    "\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 Static Reasoning Agent Functions** <a id=\"2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ITReportReviewer:\n",
    "    \"\"\"\n",
    "    A class to review sections of an IT consulting report using OpenAI's ChatCompletion API.\n",
    "\n",
    "    Process:\n",
    "    1. Initializes the reviewer with the report sections\n",
    "    2. Lets it review one section at a time using real reasoning\n",
    "    3. Stores and prints each review with feedback\n",
    "\n",
    "    Attributes:\n",
    "    sections (dict): A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "    review_history (list): A list to store the history of reviews for each section.\n",
    "\n",
    "    Methods:\n",
    "    review_section(section_name):\n",
    "        Reviews a specific section of the report using OpenAI's ChatCompletion API.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, report_sections, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
    "        \"\"\"\n",
    "        Initializes the ITReportReviewer with the given report sections, model, and temperature.\n",
    "\n",
    "        Parameters:\n",
    "        report_sections (dict): A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "        model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "        temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "        \"\"\"\n",
    "        self.sections = report_sections\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.review_history = []\n",
    "\n",
    "    def review_section(self, section_name):\n",
    "        \"\"\"\n",
    "        Reviews a specific section of the report using OpenAI's ChatCompletion API.\n",
    "\n",
    "        Parameters:\n",
    "        section_name (str): The name of the section to review.\n",
    "\n",
    "        Workflow:\n",
    "        1. Retrieves the text of the specified section from the sections dictionary.\n",
    "        2. If the section is empty or missing, prints a warning message.\n",
    "        3. Builds a prompt for reviewing the section using the build_review_prompt function.\n",
    "        4. Calls the OpenAI ChatCompletion API with tracking using the call_openai_with_tracking function.\n",
    "        5. Saves the review in the review_history attribute.\n",
    "        6. Prints the review for the specified section.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        section_text = self.sections.get(section_name, \"\")\n",
    "        if not section_text:\n",
    "            print(f\"‚ö†Ô∏è Section '{section_name}' is empty or missing.\")\n",
    "            return\n",
    "\n",
    "        # Build prompt for reviewing the section\n",
    "        messages = build_review_prompt(\n",
    "            report_text=f\"Section: {section_name}\\n\\n{section_text}\",\n",
    "            history=[]\n",
    "        )\n",
    "\n",
    "        # Get AI-generated reasoning using tracked OpenAI call\n",
    "        review = call_openai_with_tracking(messages, model=self.model, temperature=self.temperature)\n",
    "\n",
    "        # Save the review\n",
    "        self.review_history.append({\n",
    "            \"section\": section_name,\n",
    "            \"review\": review\n",
    "        })\n",
    "\n",
    "        print(f\"\\n‚úÖ Review for section '{section_name}':\\n{review}\\n{'-'*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_full_review(agent):\n",
    "    # Combine all reviews into a single prompt\n",
    "    combined_review_text = \"\"\n",
    "    for step in agent.review_history:\n",
    "        combined_review_text += f\"Section: {step['section']}\\nFeedback: {step['review']}\\n\\n\"\n",
    "\n",
    "    # Build new prompt asking for a final report assessment\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an expert IT strategy consultant reviewing an internal report assessment. \"\n",
    "                \"Summarize the overall quality of the report based on the following section reviews. \"\n",
    "                \"Highlight gaps, strengths, and suggest next steps to improve the report.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": combined_review_text\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    summary = call_openai_with_tracking(messages)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4 ReAct Reasoning Agent Functions** <a id=\"2.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActConsultantAgent:\n",
    "    \"\"\"\n",
    "    A class to review sections of an IT consulting report using the ReAct (Reason + Act) framework with OpenAI's ChatCompletion API.\n",
    "\n",
    "    Process:\n",
    "    1. Initializes the agent with the section name and text.\n",
    "    2. Builds a prompt for the ReAct framework.\n",
    "    3. Tracks the history of thoughts, actions, and observations.\n",
    "\n",
    "    Attributes:\n",
    "    section_name (str): The name of the section to review.\n",
    "    section_text (str): The text of the section to review.\n",
    "    model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "    temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "    history (list): A list to store the history of thoughts, actions, and observations.\n",
    "\n",
    "    Methods:\n",
    "    build_react_prompt():\n",
    "        Builds a prompt for the ReAct framework based on the section text and history.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, section_name, section_text, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
    "        \"\"\"\n",
    "        Initializes the ReActConsultantAgent with the given section name, section text, model, and temperature.\n",
    "\n",
    "        Parameters:\n",
    "        section_name (str): The name of the section to review.\n",
    "        section_text (str): The text of the section to review.\n",
    "        model (str): The model to use for the API call. Default is \"gpt-3.5-turbo\".\n",
    "        temperature (float): The sampling temperature to use. Higher values mean the model will take more risks. Default is 0.7.\n",
    "        \"\"\"\n",
    "        self.section_name = section_name\n",
    "        self.section_text = section_text\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.history = []\n",
    "\n",
    "    def build_react_prompt(self):\n",
    "        \"\"\"\n",
    "        Builds a prompt for the ReAct framework based on the section text and history.\n",
    "\n",
    "        Workflow:\n",
    "        1. Constructs a base prompt with the section name and text.\n",
    "        2. Iterates through the history of thoughts, actions, and observations, appending them to the base prompt.\n",
    "        3. Adds a final line asking for the next thought and action.\n",
    "\n",
    "        Returns:\n",
    "        list: A list containing a single dictionary with the role 'user' and the constructed prompt as content.\n",
    "        \"\"\"\n",
    "        base_prompt = (\n",
    "            f\"You are an expert IT strategy consultant reviewing a report section titled '{self.section_name}'.\\n\"\n",
    "            \"You are using ReAct (Reason + Act) to think through the review.\\n\\n\"\n",
    "            \"Format each response like this:\\n\"\n",
    "            \"Thought: <your reasoning>\\n\"\n",
    "            \"Action: <one of: ask_question, flag_risk, recommend_fix, summarize>\\n\\n\"\n",
    "            f\"Here is the section content:\\n{self.section_text}\\n\\n\"\n",
    "        )\n",
    "\n",
    "        for step in self.history:\n",
    "            base_prompt += f\"Thought: {step['thought']}\\n\"\n",
    "            base_prompt += f\"Action: {step['action']}\\n\"\n",
    "            base_prompt += f\"Observation: {step['observation']}\\n\\n\"\n",
    "\n",
    "        base_prompt += \"What is your next Thought and Action?\"\n",
    "\n",
    "        return [{\"role\": \"user\", \"content\": base_prompt}]\n",
    "\n",
    "    def build_react_prompt_withTools(self):\n",
    "            \"\"\"\n",
    "            Builds a prompt for the ReAct framework based on the section text and history.\n",
    "\n",
    "            Workflow:\n",
    "            1. Constructs a base prompt with the section name and text.\n",
    "            2. Iterates through the history of thoughts, actions, and observations, appending them to the base prompt.\n",
    "            3. Adds a final line asking for the next thought and action.\n",
    "            For the check_guideline action, the prompt includes a placeholder for the topic.\n",
    "            LLM infers topic from the section_text\n",
    "\n",
    "            Returns:\n",
    "            list: A list containing a single dictionary with the role 'user' and the constructed prompt as content.\n",
    "            \"\"\"\n",
    "            base_prompt = (\n",
    "                f\"You are an expert IT strategy consultant reviewing a report section titled '{self.section_name}'.\\n\"\n",
    "                \"You are using ReAct (Reason + Act) to think through the review.\\n\\n\"\n",
    "                \"Format each response like this:\\n\"\n",
    "                \"Thought: <your reasoning>\\n\"\n",
    "                \"Action: <one of: \" + format_tools_list(tool_catalog) + \"'\\n\\n\"\n",
    "            )\n",
    "\n",
    "            base_prompt += format_tool_catalog_for_prompt(tool_catalog)\n",
    "            base_prompt += f\"Here is the section content:\\n{self.section_text}\\n\\n\"\n",
    "\n",
    "            for step in self.history:\n",
    "                base_prompt += f\"Thought: {step['thought']}\\n\"\n",
    "                base_prompt += f\"Action: {step['action']}\\n\"\n",
    "                base_prompt += f\"Observation: {step['observation']}\\n\\n\"\n",
    "\n",
    "            base_prompt += \"What is your next Thought and Action?\"\n",
    "\n",
    "            return [{\"role\": \"user\", \"content\": base_prompt}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_react_loop_static(agent, max_steps=5):\n",
    "    \"\"\"\n",
    "    Runs the ReAct (Reason + Act) loop for a specified number of steps.\n",
    "\n",
    "    Purpose:\n",
    "    This function iterates through a reasoning and action loop using the ReAct framework to review a section of an IT consulting report. It generates thoughts, actions, and observations at each step, and stores the history of these steps.\n",
    "\n",
    "    Parameters:\n",
    "    agent (ReActConsultantAgent): An instance of the ReActConsultantAgent class, initialized with the section name and text.\n",
    "    max_steps (int): The maximum number of steps to run the loop. Default is 5.\n",
    "\n",
    "    Workflow:\n",
    "    1. Iterates through the loop for a maximum of `max_steps` times.\n",
    "    2. In each iteration:\n",
    "    - Calls `agent.build_react_prompt()` to construct the prompt for the ReAct framework.\n",
    "    - Calls `call_openai_with_tracking()` to get the response from the OpenAI API.\n",
    "    - Parses the response to extract the thought and action.\n",
    "    - Generates an observation based on the action.\n",
    "    - Stores the thought, action, and observation in the agent's history.\n",
    "    - Prints the result of the current step.\n",
    "    - Breaks the loop if the action is \"summarize\".\n",
    "    3. Returns the full reasoning history.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, where each dictionary contains the thought, action, and observation for each step.\n",
    "    \"\"\"\n",
    "    for step_num in range(max_steps):\n",
    "        messages = agent.build_react_prompt()\n",
    "        response = call_openai_with_tracking(messages, model=agent.model, temperature=agent.temperature)\n",
    "\n",
    "        # Parse response\n",
    "        try:\n",
    "            lines = response.strip().split(\"\\n\")\n",
    "            thought = next(line.split(\":\", 1)[1].strip() for line in lines if line.lower().startswith(\"thought\"))\n",
    "            action = next(line.split(\":\", 1)[1].strip() for line in lines if line.lower().startswith(\"action\"))\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Failed to parse model response.\")\n",
    "            break\n",
    "\n",
    "        # Generate observation based on action\n",
    "        if action == \"ask_question\":\n",
    "            observation = \"Good question to ask the client for clarification.\"\n",
    "        elif action == \"flag_risk\":\n",
    "            observation = \"This is a legitimate risk that should be addressed.\"\n",
    "        elif action == \"recommend_fix\":\n",
    "            observation = \"The recommendation improves the section's clarity and compliance.\"\n",
    "        elif action == \"summarize\":\n",
    "            observation = \"Review complete.\"\n",
    "        else:\n",
    "            observation = \"Unrecognized action.\"\n",
    "\n",
    "        # Store step\n",
    "        agent.history.append({\n",
    "            \"thought\": thought,\n",
    "            \"action\": action,\n",
    "            \"observation\": observation\n",
    "        })\n",
    "\n",
    "        # Print result of this step\n",
    "        print(f\"\\nüîÅ Step {step_num + 1}\")\n",
    "        print(f\"üß† Thought: {thought}\")\n",
    "        print(f\"‚öôÔ∏è Action: {action}\")\n",
    "        print(f\"üëÄ Observation: {observation}\")\n",
    "\n",
    "        if action == \"summarize\":\n",
    "            break\n",
    "\n",
    "    # Return full reasoning history\n",
    "    return agent.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_react_loop_check_withTool(agent, max_steps=5):\n",
    "    \"\"\"\n",
    "    Runs the ReAct (Reason + Act) loop for a specified number of steps.\n",
    "\n",
    "    Purpose:\n",
    "    This function iterates through a reasoning and action loop using the ReAct framework to review a section of an IT consulting report. It generates thoughts, actions, and observations at each step, and stores the history of these steps.\n",
    "\n",
    "    Parameters:\n",
    "    agent (ReActConsultantAgent): An instance of the ReActConsultantAgent class, initialized with the section name and text.\n",
    "    max_steps (int): The maximum number of steps to run the loop. Default is 5.\n",
    "\n",
    "    Workflow:\n",
    "    1. Iterates through the loop for a maximum of `max_steps` times.\n",
    "    2. In each iteration:\n",
    "       - Calls `agent.build_react_prompt()` to construct the prompt for the ReAct framework.\n",
    "       - Calls `call_openai_with_tracking()` to get the response from the OpenAI API.\n",
    "       - Parses the response to extract the thought and action.\n",
    "       - Generates an observation based on the action.\n",
    "       - Stores the thought, action, and observation in the agent's history.\n",
    "       - Prints the result of the current step.\n",
    "       - Breaks the loop if the action is \"summarize\".\n",
    "    3. Returns the full reasoning history.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, where each dictionary contains the thought, action, and observation for each step.\n",
    "    \"\"\"\n",
    "    for step_num in range(max_steps):\n",
    "        messages = agent.build_react_prompt_checkGuideline()\n",
    "        response = call_openai_with_tracking(messages, model=agent.model, temperature=agent.temperature)\n",
    "\n",
    "        # Parse response\n",
    "        try:\n",
    "            lines = response.strip().split(\"\\n\")\n",
    "            thought = next(line.split(\":\", 1)[1].strip() for line in lines if line.lower().startswith(\"thought\"))\n",
    "            action = next(line.split(\":\", 1)[1].strip() for line in lines if line.lower().startswith(\"action\"))\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Failed to parse model response.\")\n",
    "            break\n",
    "\n",
    "        # Generate observation based on action\n",
    "        if action.startswith(\"check_guideline\"): # tool #1: check_guideline\n",
    "            try:\n",
    "                topic = action.split(\"[\", 1)[1].rstrip(\"]\").strip('\"')\n",
    "                observation = check_guideline(topic)\n",
    "            except:\n",
    "                observation = \"‚ö†Ô∏è Could not parse check_guideline action.\"\n",
    "        elif action.startswith(\"keyword_match_in_section\"): # tool #2: keyword_match_in_section\n",
    "            try:\n",
    "                term = action.split(\"[\", 1)[1].rstrip(\"]\").strip('\"')\n",
    "                observation = keyword_match_in_section(term, agent.section_text)\n",
    "            except:\n",
    "                observation = \"‚ö†Ô∏è Could not parse keyword_match_in_section action.\"\n",
    "        elif action.startswith(\"check_timeline_feasibility\"): # tool #3: check_timeline_feasibility\n",
    "            try:\n",
    "                duration = action.split(\"[\", 1)[1].rstrip(\"]\").strip('\"')\n",
    "                observation = check_timeline_feasibility(duration)\n",
    "            except:\n",
    "                observation = \"‚ö†Ô∏è Could not parse check_timeline_feasibility action.\"\n",
    "        elif action.startswith(\"search_report\"): # tool #4: search_report\n",
    "            try:\n",
    "                term = action.split(\"[\", 1)[1].rstrip(\"]\").strip('\"')\n",
    "                observation = search_report(term, report_sections)\n",
    "            except:\n",
    "                observation = \"‚ö†Ô∏è Could not parse search_report action.\"\n",
    "        elif action == \"ask_question\": # hardcoded action\n",
    "            observation = \"Good question to ask the client for clarification.\"\n",
    "        elif action == \"flag_risk\": # hardcoded action\n",
    "            observation = \"This is a legitimate risk that should be addressed.\"\n",
    "        elif action == \"recommend_fix\": # hardcoded action \n",
    "            observation = \"The recommendation improves the section's clarity and compliance.\"\n",
    "        elif action == \"summarize\": # hardcoded action; end the loop\n",
    "            observation = \"Review complete.\"\n",
    "        else:\n",
    "            observation = \"Unrecognized action.\"\n",
    "\n",
    "        # Store step\n",
    "        agent.history.append({\n",
    "            \"thought\": thought,\n",
    "            \"action\": action,\n",
    "            \"observation\": observation\n",
    "        })\n",
    "\n",
    "        # Print result of this step\n",
    "        print(f\"\\nüîÅ Step {step_num + 1}\")\n",
    "        print(f\"üß† Thought: {thought}\")\n",
    "        print(f\"‚öôÔ∏è Action: {action}\")\n",
    "        print(f\"üëÄ Observation: {observation}\")\n",
    "\n",
    "        if action == \"summarize\":\n",
    "            break\n",
    "\n",
    "    # Return full reasoning history\n",
    "    return agent.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dicionary of tools available for ReActConsultantAgent to call\n",
    "\n",
    "tool_catalog = {\n",
    "    \"check_guideline\": {\n",
    "        \"description\": \"Look up a best practice for a given topic\",\n",
    "        \"usage\": 'check_guideline[\"cloud security\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\n",
    "            \"check_guideline[\\\"data governance\\\"]\",\n",
    "            \"check_guideline[\\\"migration strategy\\\"]\"\n",
    "        ]\n",
    "    },\n",
    "    \"keyword_match_in_section\": {\n",
    "        \"description\": \"Check if a keyword appears in the current section\",\n",
    "        \"usage\": 'keyword_match_in_section[\"encryption\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\n",
    "            \"keyword_match_in_section[\\\"stakeholders\\\"]\"\n",
    "        ]\n",
    "    },\n",
    "    \"check_timeline_feasibility\": {\n",
    "        \"description\": \"Check if a project timeline is realistic for migration\",\n",
    "        \"usage\": 'check_timeline_feasibility[\"12 weeks\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\n",
    "            \"check_timeline_feasibility[\\\"3 months\\\"]\"\n",
    "        ]\n",
    "    },\n",
    "    \"search_report\": {\n",
    "        \"description\": \"Search the entire report for a concept or term\",\n",
    "        \"usage\": 'search_report[\"data governance\"]',\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\n",
    "            \"search_report[\\\"Zero Trust\\\"]\"\n",
    "        ]\n",
    "    },\n",
    "    \"ask_question\": {\n",
    "        \"description\": \"Ask a clarifying question about the report\",\n",
    "        \"usage\": \"ask_question\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"ask_question\"]\n",
    "    },\n",
    "    \"flag_risk\": {\n",
    "        \"description\": \"Flag a gap, issue, or concern in the section\",\n",
    "        \"usage\": \"flag_risk\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"flag_risk\"]\n",
    "    },\n",
    "    \"recommend_fix\": {\n",
    "        \"description\": \"Suggest a specific improvement\",\n",
    "        \"usage\": \"recommend_fix\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"recommend_fix\"]\n",
    "    },\n",
    "    \"summarize\": {\n",
    "        \"description\": \"Summarize your review and end the loop\",\n",
    "        \"usage\": \"summarize\",\n",
    "        \"version\": \"v1.0\",\n",
    "        \"examples\": [\"summarize\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the tool catalog for display in the prompt for consumption by LLM\n",
    "\n",
    "def format_tool_catalog_for_prompt(tool_catalog):\n",
    "    \"\"\"\n",
    "    Formats the tool catalog for display in the prompt for consumption by LLM.\n",
    "\n",
    "    Purpose:\n",
    "    This function formats the tool catalog into a human-readable string that lists each tool along with its description and usage. This formatted string can be used in prompts for language models to understand the available tools.\n",
    "\n",
    "    Parameters:\n",
    "    tool_catalog (dict): A dictionary where keys are tool names and values are dictionaries containing tool metadata, including 'description' and 'usage'.\n",
    "\n",
    "    Workflow:\n",
    "    1. Initializes a list with the header \"Available tools:\".\n",
    "    2. Iterates through each tool in the tool_catalog dictionary.\n",
    "    3. For each tool, appends its name, description, and usage to the list.\n",
    "    4. Joins the list into a single string with newline characters.\n",
    "\n",
    "    Returns:\n",
    "    str: A formatted string listing all tools with their descriptions and usage.\n",
    "    \"\"\"\n",
    "    lines = [\"Available tools:\\n\"]\n",
    "    for tool, meta in tool_catalog.items():\n",
    "        lines.append(f\"- {tool} (v{meta['version']}): {meta['description']}\")\n",
    "        lines.append(f\"  Usage: {meta['usage']}\")\n",
    "        if meta.get(\"examples\"):\n",
    "            for ex in meta[\"examples\"]:\n",
    "                lines.append(f\"  Example: {ex}\")\n",
    "        lines.append(\"\")  # spacing between tools\n",
    "    return \"\\n\".join(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tools_list(tool_catalog):\n",
    "    \"\"\"\n",
    "    Formats the list of tools from the tool_catalog dictionary as a comma-separated string.\n",
    "\n",
    "    Parameters:\n",
    "    tool_catalog (dict): A dictionary where keys are tool names and values are dictionaries containing tool metadata.\n",
    "\n",
    "    Returns:\n",
    "    str: A comma-separated string of tool names.\n",
    "    \"\"\"\n",
    "    tools_list = \", \".join(tool_catalog.keys())\n",
    "    return tools_list\n",
    "\n",
    "# Example usage\n",
    "formatted_tools = format_tools_list(tool_catalog)\n",
    "print(formatted_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool #1: Check for best practices in a given section\n",
    "\n",
    "# Simulated best practices reference data\n",
    "best_practices = {\n",
    "    \"cloud security\": \"Follow NIST Cybersecurity Framework. Include access control, encryption at rest/in-transit, and regular audits.\",\n",
    "    \"data governance\": \"Establish data stewards, quality standards, lifecycle rules, and metadata documentation.\",\n",
    "    \"migration\": \"Use phased migration, sandbox testing, rollback planning, and stakeholder communication.\"\n",
    "}\n",
    "\n",
    "def check_guideline(topic):\n",
    "    \"\"\"\n",
    "    Checks for best practices related to a given topic.\n",
    "\n",
    "    Purpose:\n",
    "    This function looks up best practices for a specified topic from a predefined dictionary of best practices.\n",
    "\n",
    "    Parameters:\n",
    "    topic (str): The topic for which best practices are to be checked.\n",
    "\n",
    "    Workflow:\n",
    "    1. The function converts the topic to lowercase to ensure case-insensitive matching.\n",
    "    2. It looks up the topic in the `best_practices` dictionary.\n",
    "    3. If a matching guideline is found, it returns the guideline.\n",
    "    4. If no matching guideline is found, it returns a message indicating that no matching guideline was found.\n",
    "\n",
    "    Returns:\n",
    "    str: The best practice guideline for the specified topic, or a message indicating no matching guideline was found.\n",
    "    \"\"\"\n",
    "    return best_practices.get(topic.lower(), \"No matching guideline found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool #2: Keyword matching in a section\n",
    "# This tool helps the agent check if a keyword or concept is explicitly mentioned in the section.\n",
    "# This is great for validating whether the report includes key elements (e.g., \"encryption\", \"stakeholders\", \"Zero Trust\").  \n",
    "\n",
    "def keyword_match_in_section(term, section_text):\n",
    "    \"\"\"\n",
    "    Checks if a keyword or concept is explicitly mentioned in a section of the report.\n",
    "\n",
    "    Purpose:\n",
    "    This function helps validate whether the report includes key elements by checking if a specified keyword or concept is mentioned in the section text.\n",
    "\n",
    "    Parameters:\n",
    "    term (str): The keyword or concept to search for in the section.\n",
    "    section_text (str): The text of the section to search within.\n",
    "\n",
    "    Workflow:\n",
    "    1. Converts the keyword and section text to lowercase to ensure case-insensitive matching.\n",
    "    2. Checks if the keyword is present in the section text.\n",
    "    3. Returns a message indicating whether the keyword was found or not.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating whether the keyword was found in the section.\n",
    "    \"\"\"\n",
    "    term_lower = term.lower()\n",
    "    if term_lower in section_text.lower():\n",
    "        return f\"The keyword '{term}' was found in the section.\"\n",
    "    else:\n",
    "        return f\"The keyword '{term}' was NOT found in the section.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool #3: Check feasibility of timeline for IT migration\n",
    "# This tool helps the agent assess the feasibility of a timeline for an IT migration project.\n",
    "# It checks if the timeline is too short, potentially feasible, or reasonable for a full migration.\n",
    "\n",
    "def check_timeline_feasibility(duration_str):\n",
    "    \"\"\"\n",
    "    Checks the feasibility of a timeline for an IT migration project.\n",
    "\n",
    "    Purpose:\n",
    "    This function helps assess whether a given timeline for an IT migration project is too short, potentially feasible, or reasonable.\n",
    "\n",
    "    Parameters:\n",
    "    duration_str (str): The timeline duration as a string (e.g., \"6 months\", \"12 weeks\").\n",
    "\n",
    "    Workflow:\n",
    "    1. Converts the duration string to lowercase for consistency.\n",
    "    2. Parses the duration string to extract the numeric value and unit (weeks or months).\n",
    "    3. Converts the duration to months if it is specified in weeks.\n",
    "    4. Evaluates the duration:\n",
    "       - If less than 3 months, it is likely too short.\n",
    "       - If between 3 and 12 months, it is potentially feasible depending on complexity.\n",
    "       - If more than 12 months, it seems reasonable.\n",
    "    5. Returns a message indicating the feasibility of the timeline.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating whether the timeline is too short, potentially feasible, or reasonable.\n",
    "    \"\"\"\n",
    "    # Convert string like \"6 months\" or \"12 weeks\" to months\n",
    "    duration_str = duration_str.lower()\n",
    "    try:\n",
    "        if \"week\" in duration_str:\n",
    "            num = int(duration_str.split()[0])\n",
    "            months = num / 4\n",
    "        else:\n",
    "            num = int(duration_str.split()[0])\n",
    "            months = num\n",
    "\n",
    "        if months < 3:\n",
    "            return f\"The timeline ({duration_str}) is likely too short for a full migration.\"\n",
    "        elif 3 <= months <= 12:\n",
    "            return f\"The timeline ({duration_str}) is potentially feasible depending on complexity.\"\n",
    "        else:\n",
    "            return f\"The timeline ({duration_str}) seems reasonable for a full IT migration.\"\n",
    "    except:\n",
    "        return \"‚ö†Ô∏è Could not interpret timeline format. Please use 'X months' or 'X weeks'.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool #4: Search for a term in the entire report\n",
    "# This tool helps the agent search for a specific term in the entire consulting report.\n",
    "# It returns the sections where the term was found, if any.\n",
    "\n",
    "def search_report(term, report_sections):\n",
    "    \"\"\"\n",
    "    Searches for a specific term in the entire consulting report.\n",
    "\n",
    "    Purpose:\n",
    "    This function helps the agent search for a specific term in the entire consulting report and returns the sections where the term was found, if any.\n",
    "\n",
    "    Parameters:\n",
    "    term (str): The term to search for in the report.\n",
    "    report_sections (dict): A dictionary where keys are section headers and values are the corresponding section contents.\n",
    "\n",
    "    Workflow:\n",
    "    1. Initializes an empty list `found_in` to store the sections where the term is found.\n",
    "    2. Iterates through each section in the `report_sections` dictionary.\n",
    "    3. For each section, checks if the term (case-insensitive) is present in the section content.\n",
    "    4. If the term is found, appends the section header to the `found_in` list.\n",
    "    5. After checking all sections, returns a message indicating the sections where the term was found or a message indicating that the term was not found.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating the sections where the term was found or a message indicating that the term was not found.\n",
    "    \"\"\"\n",
    "    found_in = []\n",
    "    for section, content in report_sections.items():\n",
    "        if term.lower() in content.lower():\n",
    "            found_in.append(section)\n",
    "    if found_in:\n",
    "        return f\"The term '{term}' was found in: {', '.join(found_in)}.\"\n",
    "    else:\n",
    "        return f\"The term '{term}' was NOT found anywhere in the report.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 3: Load Data** <a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample IT consulting report (replace with real one later)\n",
    "# You can later replace this with a real one or load from a file.\n",
    "# We can add file upload later (open(\"report.txt\").read())\n",
    "sample_report = \"\"\"\n",
    "Client: HealthConnect Systems\n",
    "Industry: Healthcare\n",
    "Project: IT Modernization Assessment\n",
    "\n",
    "Summary:\n",
    "HealthConnect currently operates on-premise infrastructure for its core clinical systems. While some departments use SaaS tools, there is no centralized cloud strategy. Security policies are documented but not consistently followed. There is no formal data governance framework. Leadership has expressed interest in migrating systems to the cloud.\n",
    "\n",
    "Key Recommendations:\n",
    "1. Conduct a cloud readiness assessment.\n",
    "2. Begin phased migration of CRM and EHR systems.\n",
    "3. Establish a data governance committee.\n",
    "4. Update security protocols to align with NIST standards.\n",
    "\n",
    "Timeline: Estimated at 6‚Äì12 months for full migration planning and execution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 4: Pre-process Data** <a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Header:\n",
      "Client: HealthConnect Systems\n",
      "Industry: Healthcare\n",
      "Project: IT Modernization Assessment\n",
      "------------------------------------------------------------\n",
      "üìå Summary:\n",
      "HealthConnect currently operates on-premise infrastructure for its core clinical systems. While some departments use SaaS tools, there is no centralized cloud strategy. Security policies are documented but not consistently followed. There is no formal data governance framework. Leadership has expressed interest in migrating systems to the cloud.\n",
      "------------------------------------------------------------\n",
      "üìå Key Recommendations:\n",
      "1. Conduct a cloud readiness assessment.\n",
      "2. Begin phased migration of CRM and EHR systems.\n",
      "3. Establish a data governance committee.\n",
      "4. Update security protocols to align with NIST standards.\n",
      "Timeline: Estimated at 6‚Äì12 months for full migration planning and execution.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run it on the sample report\n",
    "report_sections = split_report_into_sections(sample_report)\n",
    "\n",
    "# Display for verification\n",
    "for section, content in report_sections.items():\n",
    "    print(f\"üìå {section}:\\n{content}\\n{'-'*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 5: Model - Basic: Single-Hop Reasoning + Static Action Loop** <a id=\"5\"></a>\n",
    "\n",
    "1. Iterate through sections of report\n",
    "2. Send each section to ChatGPT for feedback\n",
    "3. Summarize feedback \n",
    "\n",
    "## **5.1 Initialize Agent** <a id=\"5.1\"></a> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the reasoning agent\n",
    "agent = ITReportReviewer(report_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2 Run Agent** <a id=\"5.2\"></a> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Prompt: 97 tokens | Completion: 87 tokens | Total so far: 184 tokens\n",
      "üí∞ Estimated cost so far: $0.0003 USD\n",
      "\n",
      "‚úÖ Review for section 'Header':\n",
      "This header section provides a brief overview of the client, industry, and project, which is a good start. However, I would recommend including additional information such as the date of the report, the names and roles of the team members involved in the assessment, and maybe a high-level objective or scope statement for the IT modernization assessment. This will provide more context for readers and help set the stage for the rest of the report.\n",
      "------------------------------------------------------------\n",
      "üî¢ Prompt: 138 tokens | Completion: 442 tokens | Total so far: 764 tokens\n",
      "üí∞ Estimated cost so far: $0.0011 USD\n",
      "\n",
      "‚úÖ Review for section 'Summary':\n",
      "Thank you for sharing the summary of the consulting report. Here are some key points to consider and areas where further information or improvement may be needed:\n",
      "\n",
      "1. **Current State Assessment**:\n",
      "   - It's good to see a clear overview of HealthConnect's current IT infrastructure landscape. However, more details on the existing on-premise systems, SaaS tools being used, and the specific security policies that are not consistently followed would provide a more comprehensive understanding. \n",
      "   - An analysis of the reasons behind the lack of a centralized cloud strategy and the absence of a formal data governance framework would be beneficial for developing recommendations.\n",
      "\n",
      "2. **Leadership's Interest in Cloud Migration**:\n",
      "   - Understanding the motivations and expectations of the leadership regarding migrating systems to the cloud is crucial. It would be helpful to include specific drivers for this interest (e.g., cost savings, scalability, flexibility) and the desired outcomes to align recommendations accordingly.\n",
      "\n",
      "3. **Recommendations**:\n",
      "   - The summary should provide a hint or scope of the recommendations that will be presented in the detailed report. It would be beneficial to mention key areas that the recommendations will cover, such as cloud adoption strategy, data governance implementation, security policy enforcement, etc.\n",
      "\n",
      "4. **Risks and Challenges**:\n",
      "   - Identifying potential risks and challenges associated with migrating systems to the cloud, implementing data governance, and enhancing security practices is essential for proactive planning. It would be valuable to include a brief mention of these in the summary.\n",
      "\n",
      "5. **Alignment with Best Practices**:\n",
      "   - Ensure that the recommendations and proposed strategies align with industry best practices for cloud adoption, data governance, and cybersecurity. Highlighting this alignment in the summary can provide assurance of the proposed approach.\n",
      "\n",
      "6. **Clarity and Conciseness**:\n",
      "   - The summary should be clear, concise, and impactful. Ensure that the language used is straightforward and that key points are effectively communicated to engage the reader and set the stage for the detailed report.\n",
      "\n",
      "By addressing these points in the consulting report summary, you can provide a strong foundation for the detailed analysis and recommendations that will follow. Let me know if you need further assistance or clarification on any specific aspect of the report.\n",
      "------------------------------------------------------------\n",
      "üî¢ Prompt: 138 tokens | Completion: 500 tokens | Total so far: 1402 tokens\n",
      "üí∞ Estimated cost so far: $0.0021 USD\n",
      "\n",
      "‚úÖ Review for section 'Key Recommendations':\n",
      "Overall, the key recommendations provided in the report seem to be on the right track. Here are some specific points to consider:\n",
      "\n",
      "1. **Conduct a cloud readiness assessment**:\n",
      "   - It would be beneficial to outline the specific objectives of this assessment. What criteria will be used to assess readiness? Are there any existing cloud readiness frameworks or tools to leverage?\n",
      "   - Consider including the scope of the assessment (e.g., applications, data, infrastructure) to ensure a comprehensive evaluation.\n",
      "\n",
      "2. **Begin phased migration of CRM and EHR systems**:\n",
      "   - It would be helpful to elaborate on the rationale behind selecting CRM and EHR systems for migration. Are there specific business drivers or technical considerations that influenced this decision?\n",
      "   - Consider outlining the migration approach (e.g., lift-and-shift, re-platforming, re-architecting) and any dependencies or risks associated with each phase.\n",
      "\n",
      "3. **Establish a data governance committee**:\n",
      "   - Specify the roles and responsibilities of the data governance committee. Who will be part of this committee, and what decision-making authority will they have?\n",
      "   - Consider including a high-level overview of the data governance framework that will be implemented to ensure effective management of data assets.\n",
      "\n",
      "4. **Update security protocols to align with NIST standards**:\n",
      "   - It would be beneficial to provide a brief overview of the NIST standards being referenced. How will the organization ensure compliance with these standards?\n",
      "   - Consider outlining the specific security protocols that need to be updated and any potential challenges or resource requirements associated with this task.\n",
      "\n",
      "5. **Timeline**:\n",
      "   - While the estimated timeline of 6-12 months for full migration planning and execution is provided, it would be helpful to break down this timeline into specific milestones or phases. This can help track progress and identify any potential delays early on.\n",
      "\n",
      "In addition, consider addressing the following points:\n",
      "- **Risk Assessment**: It would be beneficial to include a section on risk assessment related to each key recommendation. What are the potential risks and challenges associated with each recommendation, and how will they be mitigated?\n",
      "- **Resource Planning**: Consider outlining the resource requirements (e.g., budget, expertise, tools) for implementing each recommendation to ensure successful execution.\n",
      "- **Stakeholder Engagement**: Highlight the importance of stakeholder engagement and communication throughout the implementation of these recommendations to ensure alignment and support.\n",
      "\n",
      "Overall, providing more detailed information and context for each recommendation can help stakeholders better understand the rationale behind these proposed actions and ensure\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define the order in which we want to review sections\n",
    "sections_to_review = list(report_sections.keys())\n",
    "\n",
    "# Loop through each section and generate a review\n",
    "for section in sections_to_review:\n",
    "    agent.review_section(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Prompt: 1101 tokens | Completion: 479 tokens | Total so far: 2982 tokens\n",
      "üí∞ Estimated cost so far: $0.0045 USD\n",
      "üìã Final Summary of the Report Review:\n",
      "\n",
      "The internal report assessment shows a commendable effort in evaluating HealthConnect's IT modernization needs. Here is an overview of the overall quality and areas for improvement:\n",
      "\n",
      "Strengths:\n",
      "- The report provides a clear overview of HealthConnect's current IT landscape and leadership's interest in cloud migration.\n",
      "- Key recommendations are outlined, indicating a proactive approach to addressing IT modernization challenges.\n",
      "- The report mentions risk factors and challenges, demonstrating a comprehensive analysis.\n",
      "\n",
      "Areas for Improvement:\n",
      "1. **Header Section**:\n",
      "   - Enhance the header by including the report date, team member names and roles, and a high-level objective or scope statement for clarity and context.\n",
      "\n",
      "2. **Summary**:\n",
      "   - Provide detailed insights into the existing on-premise systems, SaaS tools, and security policies at HealthConnect.\n",
      "   - Include the reasons behind the lack of a centralized cloud strategy and formal data governance framework.\n",
      "   - Specify leadership's motivations and expected outcomes for cloud migration.\n",
      "   - Offer a glimpse of the recommendations and alignment with industry best practices.\n",
      "   - Ensure clarity, conciseness, and impactful communication in summarizing the report content.\n",
      "\n",
      "3. **Key Recommendations**:\n",
      "   - Define clear objectives and criteria for the cloud readiness assessment.\n",
      "   - Elaborate on the rationale for selecting CRM and EHR systems for migration.\n",
      "   - Specify roles, responsibilities, and decision-making authority of the data governance committee.\n",
      "   - Provide an overview of the NIST standards and how security protocol updates will be ensured.\n",
      "   - Break down the migration timeline into specific milestones for better tracking.\n",
      "   - Address risk assessment, resource planning, and stakeholder engagement for each recommendation.\n",
      "\n",
      "Next Steps:\n",
      "1. **Enhance Detailing**: Provide more detailed insights into the existing IT landscape and reasons behind identified gaps.\n",
      "2. **Contextualize Recommendations**: Clearly explain the rationale and approach for each key recommendation, aligning them with industry best practices.\n",
      "3. **Engage Stakeholders**: Emphasize the importance of stakeholder involvement and communication throughout the IT modernization process.\n",
      "4. **Actionable Timeline**: Develop a detailed timeline with milestones to facilitate progress tracking and early issue identification.\n",
      "5. **Risk Mitigation**: Include a risk assessment section to identify potential obstacles and outline mitigation strategies.\n",
      "\n",
      "By implementing these suggestions, the report can be strengthened to provide a more robust foundation for HealthConnect's IT modernization journey.\n"
     ]
    }
   ],
   "source": [
    "# Call the summarize_full_review function to get the final summary\n",
    "final_summary = summarize_full_review(agent)\n",
    "print(\"üìã Final Summary of the Report Review:\\n\")\n",
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 6: Model - ReAct** <a id=\"6\"></a>\n",
    "\n",
    "1. **Think** about each section (with ChatGPT)\n",
    "2. Decide on and take an **action**\n",
    "3. **Observe** the results and loop back to step 1 with new reasoning\n",
    "\n",
    "## **6.1 Simple Agent - Predefined Actions** <a id=\"6.1\"></a> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Prompt: 139 tokens | Completion: 61 tokens | Total so far: 3182 tokens\n",
      "üí∞ Estimated cost so far: $0.0048 USD\n",
      "\n",
      "üîÅ Step 1\n",
      "üß† Thought: The lack of a centralized cloud strategy and inconsistent adherence to security policies pose significant risks to the organization's data and systems.\n",
      "‚öôÔ∏è Action: flag_risk\n",
      "üëÄ Observation: This is a legitimate risk that should be addressed.\n",
      "üî¢ Prompt: 184 tokens | Completion: 52 tokens | Total so far: 3418 tokens\n",
      "üí∞ Estimated cost so far: $0.0051 USD\n",
      "\n",
      "üîÅ Step 2\n",
      "üß† Thought: Migrating systems to the cloud without a formal data governance framework in place could lead to data management challenges and potential compliance issues.\n",
      "‚öôÔ∏è Action: recommend_fix\n",
      "üëÄ Observation: The recommendation improves the section's clarity and compliance.\n",
      "üî¢ Prompt: 230 tokens | Completion: 47 tokens | Total so far: 3695 tokens\n",
      "üí∞ Estimated cost so far: $0.0055 USD\n",
      "\n",
      "üîÅ Step 3\n",
      "üß† Thought: Leadership's interest in migrating systems to the cloud presents an opportunity to enhance the organization's agility and scalability.\n",
      "‚öôÔ∏è Action: recommend_fix\n",
      "üëÄ Observation: The recommendation improves the section's clarity and compliance.\n",
      "üî¢ Prompt: 271 tokens | Completion: 54 tokens | Total so far: 4020 tokens\n",
      "üí∞ Estimated cost so far: $0.0060 USD\n",
      "\n",
      "üîÅ Step 4\n",
      "üß† Thought: It is important to assess the current on-premise infrastructure and determine the feasibility and potential challenges of migrating systems to the cloud.\n",
      "‚öôÔ∏è Action: ask_question\n",
      "üëÄ Observation: Good question to ask the client for clarification.\n",
      "üî¢ Prompt: 315 tokens | Completion: 54 tokens | Total so far: 4389 tokens\n",
      "üí∞ Estimated cost so far: $0.0066 USD\n",
      "\n",
      "üîÅ Step 5\n",
      "üß† Thought: It is crucial to evaluate the existing SaaS tools being used in different departments to ensure they align with the overall IT strategy and security policies.\n",
      "‚öôÔ∏è Action: ask_question\n",
      "üëÄ Observation: Good question to ask the client for clarification.\n"
     ]
    }
   ],
   "source": [
    "# Choose a section to run ReAct on\n",
    "section_name = \"Summary\"\n",
    "section_text = report_sections.get(section_name, \"\")\n",
    "\n",
    "# Initialize the ReAct agent\n",
    "react_agent = ReActConsultantAgent(section_name, section_text)\n",
    "\n",
    "# Run the ReAct loop\n",
    "react_review_history = run_react_loop_static(react_agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.2 Agent 2 - Simple Tools** <a id=\"6.2\"></a> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Prompt: 206 tokens | Completion: 31 tokens | Total so far: 4626 tokens\n",
      "üí∞ Estimated cost so far: $0.0069 USD\n",
      "\n",
      "üîÅ Step 1\n",
      "üß† Thought: It is important to ensure that the recommendations align with industry best practices and address potential risks.\n",
      "‚öôÔ∏è Action: check_guideline[\"cloud readiness assessment\"]\n",
      "üëÄ Observation: No matching guideline found.\n",
      "üî¢ Prompt: 244 tokens | Completion: 110 tokens | Total so far: 4980 tokens\n",
      "üí∞ Estimated cost so far: $0.0075 USD\n",
      "\n",
      "üîÅ Step 2\n",
      "üß† Thought: Since there was no specific guideline found for cloud readiness assessment, it may be beneficial to further research industry best practices in this area to ensure the recommendation is comprehensive and effective.\n",
      "‚öôÔ∏è Action: recommend_fix\n",
      "üëÄ Observation: The recommendation improves the section's clarity and compliance.\n",
      "üî¢ Prompt: 298 tokens | Completion: 28 tokens | Total so far: 5306 tokens\n",
      "üí∞ Estimated cost so far: $0.0080 USD\n",
      "\n",
      "üîÅ Step 3\n",
      "üß† Thought: The phased migration of CRM and EHR systems could introduce potential risks if not properly planned and executed.\n",
      "‚öôÔ∏è Action: flag_risk\n",
      "üëÄ Observation: This is a legitimate risk that should be addressed.\n",
      "üî¢ Prompt: 339 tokens | Completion: 36 tokens | Total so far: 5681 tokens\n",
      "üí∞ Estimated cost so far: $0.0085 USD\n",
      "\n",
      "üîÅ Step 4\n",
      "üß† Thought: It would be helpful to know if there are specific risks or challenges associated with the migration of CRM and EHR systems that need to be addressed.\n",
      "‚öôÔ∏è Action: ask_question\n",
      "üëÄ Observation: Good question to ask the client for clarification.\n",
      "üî¢ Prompt: 387 tokens | Completion: 31 tokens | Total so far: 6099 tokens\n",
      "üí∞ Estimated cost so far: $0.0091 USD\n",
      "\n",
      "üîÅ Step 5\n",
      "üß† Thought: Establishing a data governance committee is a crucial step for ensuring data quality, security, and compliance throughout the migration process.\n",
      "‚öôÔ∏è Action: recommend_fix\n",
      "üëÄ Observation: The recommendation improves the section's clarity and compliance.\n"
     ]
    }
   ],
   "source": [
    "# Choose a section to run ReAct on\n",
    "section_name = \"Key Recommendations\"\n",
    "section_text = report_sections.get(section_name, \"\")\n",
    "\n",
    "# Initialize the ReAct agent\n",
    "react_agent = ReActConsultantAgent(section_name, section_text)\n",
    "\n",
    "# Run the ReAct loop\n",
    "react_review_history = run_react_loop_check_withTool(react_agent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hockey_ai",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
